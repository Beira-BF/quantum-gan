{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/junde/miniconda3/envs/kongsr-rdkit/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/junde/miniconda3/envs/kongsr-rdkit/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/junde/miniconda3/envs/kongsr-rdkit/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/junde/miniconda3/envs/kongsr-rdkit/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/junde/miniconda3/envs/kongsr-rdkit/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:521: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/junde/miniconda3/envs/kongsr-rdkit/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import pennylane as qml\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import csv\n",
    "import pandas as pd\n",
    "import argparse\n",
    "import os\n",
    "import math\n",
    "import datetime\n",
    "import time\n",
    "from frechetdist import frdist\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torch.utils.data as data\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "from solver import Solver\n",
    "from data_loader import get_loader\n",
    "from torch.backends import cudnn\n",
    "from utils import *\n",
    "from models import Generator, Discriminator\n",
    "from data.sparse_molecular_dataset import SparseMolecularDataset\n",
    "from rdkit import Chem\n",
    "\n",
    "def str2bool(v):\n",
    "    return v.lower() in ('true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=128, beta1=0.5, beta2=0.999, d_conv_dim=[[128, 64], 128, [128, 64]], d_lr=0.0001, d_repeat_num=6, dropout=0.0, g_conv_dim=[128], g_lr=0.0001, g_repeat_num=6, lambda_cls=1, lambda_gp=10, lambda_rec=10, log_dir='molgan/logs', log_step=10, lr_update_step=1000, mode='train', model_save_dir='molgan/models', model_save_step=1000, mol_data_dir='data/gdb9_9nodes.sparsedataset', n_critic=5, num_iters=20000, num_iters_decay=2000, num_workers=1, post_method='softmax', result_dir='molgan/results', resume_iters=None, sample_dir='molgan/samples', sample_step=1000, test_iters=10000, use_tensorboard=False, z_dim=8)\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "# Model configuration.\n",
    "parser.add_argument('--z_dim', type=int, default=8, help='dimension of domain labels')\n",
    "parser.add_argument('--g_conv_dim', default=[128], help='number of conv filters in the first layer of G')\n",
    "parser.add_argument('--d_conv_dim', type=int, default=[[128, 64], 128, [128, 64]], help='number of conv filters in the first layer of D')\n",
    "parser.add_argument('--g_repeat_num', type=int, default=6, help='number of residual blocks in G')\n",
    "parser.add_argument('--d_repeat_num', type=int, default=6, help='number of strided conv layers in D')\n",
    "parser.add_argument('--lambda_cls', type=float, default=1, help='weight for domain classification loss')\n",
    "parser.add_argument('--lambda_rec', type=float, default=10, help='weight for reconstruction loss')\n",
    "parser.add_argument('--lambda_gp', type=float, default=10, help='weight for gradient penalty')\n",
    "parser.add_argument('--post_method', type=str, default='softmax', choices=['softmax', 'soft_gumbel', 'hard_gumbel'])\n",
    "\n",
    "# Training configuration.\n",
    "parser.add_argument('--batch_size', type=int, default=128, help='mini-batch size')\n",
    "parser.add_argument('--num_iters', type=int, default=20000, help='number of total iterations for training D')\n",
    "parser.add_argument('--num_iters_decay', type=int, default=2000, help='number of iterations for decaying lr')\n",
    "parser.add_argument('--g_lr', type=float, default=0.0001, help='learning rate for G')\n",
    "parser.add_argument('--d_lr', type=float, default=0.0001, help='learning rate for D')\n",
    "parser.add_argument('--dropout', type=float, default=0., help='dropout rate')\n",
    "parser.add_argument('--n_critic', type=int, default=5, help='number of D updates per each G update')\n",
    "parser.add_argument('--beta1', type=float, default=0.5, help='beta1 for Adam optimizer')\n",
    "parser.add_argument('--beta2', type=float, default=0.999, help='beta2 for Adam optimizer')\n",
    "parser.add_argument('--resume_iters', type=int, default=None, help='resume training from this step')\n",
    "\n",
    "# Test configuration.\n",
    "parser.add_argument('--test_iters', type=int, default=10000, help='test model from this step')\n",
    "\n",
    "# Miscellaneous.\n",
    "parser.add_argument('--num_workers', type=int, default=1)\n",
    "parser.add_argument('--mode', type=str, default='train', choices=['train', 'test'])\n",
    "parser.add_argument('--use_tensorboard', type=str2bool, default=False)\n",
    "\n",
    "# Directories.\n",
    "parser.add_argument('--mol_data_dir', type=str, default='data/gdb9_9nodes.sparsedataset')\n",
    "parser.add_argument('--log_dir', type=str, default='molgan/logs')\n",
    "parser.add_argument('--model_save_dir', type=str, default='molgan/models')\n",
    "parser.add_argument('--sample_dir', type=str, default='molgan/samples')\n",
    "parser.add_argument('--result_dir', type=str, default='molgan/results')\n",
    "\n",
    "# Step size.\n",
    "parser.add_argument('--log_step', type=int, default=10)\n",
    "parser.add_argument('--sample_step', type=int, default=1000)\n",
    "parser.add_argument('--model_save_step', type=int, default=1000)\n",
    "parser.add_argument('--lr_update_step', type=int, default=1000)\n",
    "\n",
    "config = parser.parse_known_args()[0]\n",
    "print(config)\n",
    "\n",
    "# For fast training.\n",
    "cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = qml.device('default.qubit', wires=4)\n",
    "@qml.qnode(dev, interface='torch')\n",
    "def gen_circuit_1(w):\n",
    "    # random noise as generator input\n",
    "    z1 = random.uniform(-1, 1)\n",
    "    z2 = random.uniform(-1, 1)\n",
    "    layers = 1\n",
    "    qubits = 4\n",
    "    \n",
    "    \n",
    "    # construct generator circuit for both atom vector and node matrix\n",
    "    for i in range(qubits):\n",
    "        qml.RY(np.arcsin(z1), wires=i)\n",
    "        qml.RZ(np.arcsin(z2), wires=i)\n",
    "    for l in range(layers):\n",
    "        for i in range(qubits):\n",
    "            qml.RY(w[i], wires=i)\n",
    "            print(i)\n",
    "        for i in range(qubits-1):\n",
    "            qml.CNOT(wires=[i, i+1])\n",
    "            qml.RZ(w[i+qubits], wires=i+1)\n",
    "            print(i+qubits)\n",
    "            qml.CNOT(wires=[i, i+1])\n",
    "    return [qml.expval(qml.PauliZ(i)) for i in range(qubits)]\n",
    "\n",
    "@qml.qnode(dev, interface='torch')\n",
    "def gen_circuit_2(w):\n",
    "    # random noise as generator input\n",
    "    z1 = random.uniform(-1, 1)\n",
    "    z2 = random.uniform(-1, 1)\n",
    "    layers = 1\n",
    "    qubits = 4\n",
    "    \n",
    "    # construct generator circuit for both atom vector and node matrix\n",
    "    for i in range(qubits):\n",
    "        qml.RY(np.arcsin(z1), wires=i)\n",
    "        qml.RZ(np.arcsin(z2), wires=i)\n",
    "    for l in range(layers):\n",
    "        for i in range(qubits):\n",
    "            qml.RY(w[i+7], wires=i)\n",
    "            print(i+7)\n",
    "        for i in range(qubits-1):\n",
    "            qml.CNOT(wires=[i, i+1])\n",
    "            qml.RZ(w[i+qubits+7], wires=i+1)\n",
    "            print(i+qubits+7)\n",
    "            qml.CNOT(wires=[i, i+1])\n",
    "    return [qml.expval(qml.PauliZ(i)) for i in range(qubits)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.6741, 0.8815, 0.2990, 0.2667, 0.5196, 0.9200, 0.9105, 0.9229],\n",
       "       dtype=torch.float64, grad_fn=<CatBackward>)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = torch.tensor(list(np.random.rand(14)*2-1), requires_grad=True)\n",
    "torch.cat([gen_circuit_1(w), gen_circuit_2(w)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 12 is out of bounds for axis 0 with size 12",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-123-c3ac968b6fff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msample_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgen_circuit_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen_circuit_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-123-c3ac968b6fff>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msample_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgen_circuit_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen_circuit_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/kongsr-rdkit/lib/python3.6/site-packages/pennylane/interfaces/torch.py\u001b[0m in \u001b[0;36mcustom_apply\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0;31m# [keyword_values[k] for k in sorted(keyword_positions, key=keyword_positions.get)]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_TorchQNode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyword_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcustom_apply\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/kongsr-rdkit/lib/python3.6/site-packages/pennylane/interfaces/torch.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, input_kwargs, *input_)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m             \u001b[0;31m# evaluate the QNode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mqnode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/kongsr-rdkit/lib/python3.6/site-packages/pennylane/qnodes/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    797\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    798\u001b[0m         \u001b[0;34m\"\"\"Wrapper for :meth:`BaseQNode.evaluate`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 799\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    800\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    801\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/kongsr-rdkit/lib/python3.6/site-packages/pennylane/qnodes/base.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcircuit\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmutable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_construct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/kongsr-rdkit/lib/python3.6/site-packages/pennylane/qnodes/jacobian.py\u001b[0m in \u001b[0;36m_construct\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0meach\u001b[0m \u001b[0mpositional\u001b[0m \u001b[0mparameter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \"\"\"\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_construct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpar_to_grad_method\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_best_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable_deps\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/kongsr-rdkit/lib/python3.6/site-packages/pennylane/qnodes/base.py\u001b[0m in \u001b[0;36m_construct\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    563\u001b[0m                     \u001b[0;31m# it's ok to directly pass auxiliary arguments since the circuit is re-constructed each time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m                     \u001b[0;31m# (positional args must be replaced because parameter-shift differentiation requires Variables)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 565\u001b[0;31m                     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marg_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    566\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m                     \u001b[0;31m# TODO: Maybe we should only convert the kwarg_vars that were actually given\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-122-85a551879f7b>\u001b[0m in \u001b[0;36mgen_circuit_2\u001b[0;34m(w)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqubits\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0mqml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCNOT\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwires\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mqml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRZ\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mqubits\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwires\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mqubits\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mqml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCNOT\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwires\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 12 is out of bounds for axis 0 with size 12"
     ]
    }
   ],
   "source": [
    "sample_list = [torch.cat([gen_circuit_1(w), gen_circuit_2(w)]) for i in range(7)]\n",
    "z = torch.stack(tuple(sample_list)).to('cpu').float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = qml.device('default.qubit', wires=2)\n",
    "@qml.qnode(dev, interface='torch')\n",
    "def gen_circuit_1(w):\n",
    "    # random noise as generator input\n",
    "    z1 = random.uniform(-1, 1)\n",
    "    z2 = random.uniform(-1, 1)\n",
    "    layers = 1\n",
    "    qubits = 2\n",
    "    \n",
    "    \n",
    "    # construct generator circuit for both atom vector and node matrix\n",
    "    for i in range(qubits):\n",
    "        qml.RY(np.arcsin(z1), wires=i)\n",
    "        qml.RZ(np.arcsin(z2), wires=i)\n",
    "    for l in range(layers):\n",
    "        for i in range(qubits):\n",
    "            qml.RY(w[i], wires=i)\n",
    "        for i in range(qubits-1):\n",
    "            qml.CNOT(wires=[i, i+1])\n",
    "            qml.RZ(w[i+qubits], wires=i+1)\n",
    "            qml.CNOT(wires=[i, i+1])\n",
    "    return [qml.expval(qml.PauliZ(i)) for i in range(qubits)]\n",
    "\n",
    "@qml.qnode(dev, interface='torch')\n",
    "def gen_circuit_2(w):\n",
    "    # random noise as generator input\n",
    "    z1 = random.uniform(-1, 1)\n",
    "    z2 = random.uniform(-1, 1)\n",
    "    layers = 1\n",
    "    qubits = 2\n",
    "    \n",
    "    # construct generator circuit for both atom vector and node matrix\n",
    "    for i in range(qubits):\n",
    "        qml.RY(np.arcsin(z1), wires=i)\n",
    "        qml.RZ(np.arcsin(z2), wires=i)\n",
    "    for l in range(layers):\n",
    "        for i in range(qubits):\n",
    "            qml.RY(w[i+3], wires=i)\n",
    "        for i in range(qubits-1):\n",
    "            qml.CNOT(wires=[i, i+1])\n",
    "            qml.RZ(w[i+qubits+3], wires=i+1)\n",
    "            qml.CNOT(wires=[i, i+1])\n",
    "    return [qml.expval(qml.PauliZ(i)) for i in range(qubits)]\n",
    "\n",
    "@qml.qnode(dev, interface='torch')\n",
    "def gen_circuit_3(w):\n",
    "    # random noise as generator input\n",
    "    z1 = random.uniform(-1, 1)\n",
    "    z2 = random.uniform(-1, 1)\n",
    "    layers = 1\n",
    "    qubits = 2\n",
    "    \n",
    "    # construct generator circuit for both atom vector and node matrix\n",
    "    for i in range(qubits):\n",
    "        qml.RY(np.arcsin(z1), wires=i)\n",
    "        qml.RZ(np.arcsin(z2), wires=i)\n",
    "    for l in range(layers):\n",
    "        for i in range(qubits):\n",
    "            qml.RY(w[i+3*2], wires=i)\n",
    "        for i in range(qubits-1):\n",
    "            qml.CNOT(wires=[i, i+1])\n",
    "            qml.RZ(w[i+qubits+3*2], wires=i+1)\n",
    "            qml.CNOT(wires=[i, i+1])\n",
    "    return [qml.expval(qml.PauliZ(i)) for i in range(qubits)]\n",
    "\n",
    "@qml.qnode(dev, interface='torch')\n",
    "def gen_circuit_4(w):\n",
    "    # random noise as generator input\n",
    "    z1 = random.uniform(-1, 1)\n",
    "    z2 = random.uniform(-1, 1)\n",
    "    layers = 1\n",
    "    qubits = 2\n",
    "    \n",
    "    # construct generator circuit for both atom vector and node matrix\n",
    "    for i in range(qubits):\n",
    "        qml.RY(np.arcsin(z1), wires=i)\n",
    "        qml.RZ(np.arcsin(z2), wires=i)\n",
    "    for l in range(layers):\n",
    "        for i in range(qubits):\n",
    "            qml.RY(w[i+3*3], wires=i)\n",
    "        for i in range(qubits-1):\n",
    "            qml.CNOT(wires=[i, i+1])\n",
    "            qml.RZ(w[i+qubits+3*3], wires=i+1)\n",
    "            qml.CNOT(wires=[i, i+1])\n",
    "    return [qml.expval(qml.PauliZ(i)) for i in range(qubits)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([0.2500, 0.5290, 0.5061, 0.7878, 0.5537, 0.4524, 0.9821, 0.8538],\n",
       "        dtype=torch.float64, grad_fn=<CatBackward>),\n",
       " tensor([0.2800, 0.5252, 0.8731, 0.1593, 0.9440, 0.9763, 0.8372, 0.9997],\n",
       "        dtype=torch.float64, grad_fn=<CatBackward>),\n",
       " tensor([0.9743, 0.8851, 0.2375, 0.9552, 0.6988, 0.6503, 0.8191, 0.9968],\n",
       "        dtype=torch.float64, grad_fn=<CatBackward>)]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = torch.tensor(list(np.random.rand(12)*2-1), requires_grad=True)\n",
    "[torch.cat([gen_circuit_1(w), gen_circuit_2(w), gen_circuit_3(w), gen_circuit_4(w)]) for i in range(3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = qml.device('default.qubit', wires=8)\n",
    "@qml.qnode(dev, interface='torch')\n",
    "def gen_circuit(w):\n",
    "    # random noise as generator input\n",
    "    z1 = random.uniform(-1, 1)\n",
    "    z2 = random.uniform(-1, 1)\n",
    "    layers = 2\n",
    "    qubits = 8\n",
    "    \n",
    "    # construct generator circuit for both atom vector and node matrix\n",
    "    for i in range(qubits):\n",
    "        qml.RY(np.arcsin(z1), wires=i)\n",
    "        qml.RZ(np.arcsin(z2), wires=i)\n",
    "    for l in range(layers):\n",
    "        for i in range(qubits):\n",
    "            qml.RY(w[i+15*l], wires=i)\n",
    "        for i in range(qubits-1):\n",
    "            qml.CNOT(wires=[i, i+1])\n",
    "            qml.RZ(w[i+qubits+15*l], wires=i+1)\n",
    "            qml.CNOT(wires=[i, i+1])\n",
    "    return [qml.expval(qml.PauliZ(i)) for i in range(qubits)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'gen_circuit_3' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-b0d3a56dccd1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgen_circuit_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen_circuit_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen_circuit_3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen_circuit_4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'gen_circuit_3' is not defined"
     ]
    }
   ],
   "source": [
    "w = torch.tensor(list(np.random.rand(30)*2-1), requires_grad=True)\n",
    "torch.cat([gen_circuit_1(w), gen_circuit_2(w), gen_circuit_3(w), gen_circuit_4(w)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=8, out_features=128, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Dropout(p=0.0, inplace=True)\n",
      "  )\n",
      "  (edges_layer): Linear(in_features=128, out_features=405, bias=True)\n",
      "  (nodes_layer): Linear(in_features=128, out_features=45, bias=True)\n",
      "  (dropoout): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "G\n",
      "The number of parameters: 59202\n",
      "Discriminator(\n",
      "  (gcn_layer): GraphConvolution(\n",
      "    (linear1): Linear(in_features=5, out_features=128, bias=True)\n",
      "    (linear2): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (dropout): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (agg_layer): GraphAggregation(\n",
      "    (sigmoid_linear): Sequential(\n",
      "      (0): Linear(in_features=69, out_features=128, bias=True)\n",
      "      (1): Sigmoid()\n",
      "    )\n",
      "    (tanh_linear): Sequential(\n",
      "      (0): Linear(in_features=69, out_features=128, bias=True)\n",
      "      (1): Tanh()\n",
      "    )\n",
      "    (dropout): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (linear_layer): Sequential(\n",
      "    (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (1): Dropout(p=0.0, inplace=False)\n",
      "    (2): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (3): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (output_layer): Linear(in_features=64, out_features=1, bias=True)\n",
      ")\n",
      "D\n",
      "The number of parameters: 51777\n"
     ]
    }
   ],
   "source": [
    "self = Solver(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed_all(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NP score': 0.900098276214917,\n",
       " 'QED score': 0.45752609736227534,\n",
       " 'logP score': 0.2837258677101192,\n",
       " 'SA score': 0.2976284457836144,\n",
       " 'diversity score': 0.737572618801331,\n",
       " 'drugcandidate score': 0.3451985005801226,\n",
       " 'valid score': 100.0,\n",
       " 'unique score': 100.0,\n",
       " 'novel score': 0.0}"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ", novel score: 0.0000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loss = {}\n",
    "log = ''\n",
    "qed = []\n",
    "logp = []\n",
    "sa = []\n",
    "\n",
    "#FD Score experiments\n",
    "for i in range(0, 1):\n",
    "    mols, _, _, a, x, _, _, _, _ = self.data.next_train_batch(self.batch_size)\n",
    "#     try:\n",
    "#         R2_ab = R1_ab\n",
    "#         R2_b = R1_b\n",
    "#     except:\n",
    "#         R2_ab = [list(x[i]) + list(a[i].reshape(-1))  for i in range(self.batch_size)]\n",
    "#         R2_b = [list(a[i].reshape(-1))  for i in range(self.batch_size)]\n",
    "#     R1_ab = [list(x[i]) + list(a[i].reshape(-1))  for i in range(self.batch_size)]\n",
    "#     R1_b = [list(a[i].reshape(-1))  for i in range(self.batch_size)]\n",
    "    \n",
    "#     fd_ab.append(frdist(R1_ab, R2_ab))\n",
    "#     fd_b.append(frdist(R1_b, R2_b))\n",
    "    \n",
    "    m0, m1 = all_scores(mols, self.data, norm=True)     # 'mols' is output of Fake Reward\n",
    "    m0 = {k: np.array(v)[np.nonzero(v)].mean() for k, v in m0.items()}\n",
    "    m0.update(m1)\n",
    "    loss.update(m0)\n",
    "    for tag, value in loss.items():\n",
    "        if tag == 'QED score':\n",
    "            qed.append(round(value, 4))\n",
    "        if tag == 'logP score':\n",
    "            logp.append(round(value, 4))\n",
    "        if tag == 'SA score':\n",
    "            sa.append(round(value, 4))\n",
    "        \n",
    "    log += \", {}: {:.4f}\".format(tag, value)\n",
    "    print(log)\n",
    "    log = ''\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "tensor([ 0.4410, -0.3494, -0.1709, -0.6289, -0.8922,  0.2600, -0.5394,  0.7226,\n",
      "         0.8922,  0.0478, -0.0037,  0.7795, -0.9518,  0.2976,  0.0188])\n",
      "2020-11-16 14:11:32\tEpoch 5/20000 \t[D loss: 10.438986]\t[G loss: 0.006729]\n"
     ]
    }
   ],
   "source": [
    "# Learning rate cache for decaying.\n",
    "g_lr = self.g_lr\n",
    "d_lr = self.d_lr\n",
    "gen_weights = torch.tensor([0.44093025,-0.3495443,-0.17103225,-0.62883323,-0.89205253,0.25990093,-0.539537,0.72252595,0.89228415,\\\n",
    "                            0.04769561,-0.0035566252,0.7793881,-0.95167345,0.29773384,0.018899115], requires_grad=True) #16923\n",
    "self.g_optimizer = torch.optim.Adam(list(self.G.parameters())+[gen_weights],\n",
    "                                    self.g_lr, [self.beta1, self.beta2])\n",
    "self.d_optimizer = torch.optim.Adam(self.D.parameters(), self.d_lr, [self.beta1, self.beta2]) #+[gen_weights]\n",
    "\n",
    "# Start training from scratch or resume training.\n",
    "start_iters = 0\n",
    "self.resume_iters = 0\n",
    "if self.resume_iters:\n",
    "    start_iters = self.resume_iters\n",
    "    self.restore_model(self.resume_iters)\n",
    "    \n",
    "# Start training.\n",
    "print('Start training...')\n",
    "\n",
    "for i in range(start_iters, self.num_iters):\n",
    "    start_time = time.time()\n",
    "    mols, _, _, a, x, _, _, _, _ = self.data.next_train_batch(self.batch_size)\n",
    "    real_mols = mols\n",
    "\n",
    "    # =================================================================================== #\n",
    "    #                             1. Preprocess input data                                #\n",
    "    # =================================================================================== #\n",
    "\n",
    "    a = torch.from_numpy(a).to(self.device).long()            # Adjacency.\n",
    "    x = torch.from_numpy(x).to(self.device).long()            # Nodes.\n",
    "    a_tensor = self.label2onehot(a, self.b_dim)\n",
    "    x_tensor = self.label2onehot(x, self.m_dim)\n",
    "    sample_list = [gen_circuit(gen_weights) for i in range(self.batch_size)]\n",
    "    z = torch.stack(tuple(sample_list)).to(self.device).float()\n",
    "#         z = self.sample_z(self.batch_size)\n",
    "#         z = torch.from_numpy(z).to(self.device).float()\n",
    "\n",
    "    # =================================================================================== #\n",
    "    #                             2. Train the discriminator                              #\n",
    "    # =================================================================================== #\n",
    "\n",
    "    # Compute loss with real images.\n",
    "    logits_real, features_real = self.D(a_tensor, None, x_tensor)\n",
    "    d_loss_real = - torch.mean(logits_real)\n",
    "\n",
    "    # Compute loss with fake images.\n",
    "    edges_logits, nodes_logits = self.G(z)\n",
    "    # Postprocess with Gumbel softmax\n",
    "    (edges_hat, nodes_hat) = self.postprocess((edges_logits, nodes_logits), self.post_method)\n",
    "    logits_fake, features_fake = self.D(edges_hat, None, nodes_hat)\n",
    "    d_loss_fake = torch.mean(logits_fake)\n",
    "\n",
    "    # Compute loss for gradient penalty.\n",
    "    eps = torch.rand(logits_real.size(0),1,1,1).to(self.device)\n",
    "    x_int0 = (eps * a_tensor + (1. - eps) * edges_hat).requires_grad_(True)\n",
    "    x_int1 = (eps.squeeze(-1) * x_tensor + (1. - eps.squeeze(-1)) * nodes_hat).requires_grad_(True)\n",
    "    grad0, grad1 = self.D(x_int0, None, x_int1)\n",
    "    d_loss_gp = self.gradient_penalty(grad0, x_int0) + self.gradient_penalty(grad1, x_int1)\n",
    "\n",
    "\n",
    "    # Backward and optimize.\n",
    "    d_loss = d_loss_fake + d_loss_real + self.lambda_gp * d_loss_gp\n",
    "    self.reset_grad()\n",
    "    d_loss.backward(retain_graph=True)\n",
    "    self.d_optimizer.step()\n",
    "\n",
    "    # =================================================================================== #\n",
    "    #                               3. Train the generator                                #\n",
    "    # =================================================================================== #\n",
    "\n",
    "    if (i+1) % self.n_critic == 0:\n",
    "        # Z-to-target\n",
    "        edges_logits, nodes_logits = self.G(z)\n",
    "        # Postprocess with Gumbel softmax\n",
    "        (edges_hat, nodes_hat) = self.postprocess((edges_logits, nodes_logits), self.post_method)\n",
    "        logits_fake, features_fake = self.D(edges_hat, None, nodes_hat)\n",
    "        g_loss_fake = - torch.mean(logits_fake)\n",
    "\n",
    "        # Fake Reward\n",
    "        (edges_hard, nodes_hard) = self.postprocess((edges_logits, nodes_logits), 'hard_gumbel')\n",
    "        edges_hard, nodes_hard = torch.max(edges_hard, -1)[1], torch.max(nodes_hard, -1)[1]\n",
    "        mols = [self.data.matrices2mol(n_.data.cpu().numpy(), e_.data.cpu().numpy(), strict=True)\n",
    "                for e_, n_ in zip(edges_hard, nodes_hard)]\n",
    "        rewardF = torch.mean(torch.from_numpy(self.reward(mols)).to(self.device))\n",
    "        rewardR = torch.mean(torch.from_numpy(self.reward(real_mols)).to(self.device))\n",
    "\n",
    "        # Backward and optimize.\n",
    "        g_loss = g_loss_fake\n",
    "        self.reset_grad()\n",
    "        g_loss.backward(retain_graph=True)\n",
    "        self.g_optimizer.step()\n",
    "        \n",
    "        R=[list(x[i]) + list(a[i].reshape(-1))  for i in range(self.batch_size)]\n",
    "        F=[list(nodes_hard[i]) + list(edges_hard[i].reshape(-1))  for i in range(self.batch_size)]\n",
    "        fd_score = frdist(R,F)\n",
    "        \n",
    "        print(gen_weights.detach())\n",
    "        print(\n",
    "            \"%s\\tEpoch %d/%d \\t[D loss: %f]\\t[G loss: %f]\"\n",
    "            % (datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"), i+1, self.num_iters, d_loss.item(), g_loss.item())\n",
    "        )  \n",
    "\n",
    "        et = time.time() - start_time\n",
    "        with open('new_metric_scores_8q.csv', 'a') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([i+1, et, d_loss.item(), d_loss_real.item(), \\\n",
    "                             d_loss_fake.item(), g_loss.item(), rewardR.item(), rewardF.item()])\n",
    "    \n",
    "    \n",
    "    # =================================================================================== #\n",
    "    #                                 4. Miscellaneous                                    #\n",
    "    # =================================================================================== #\n",
    "    \n",
    "    # Save model checkpoints.\n",
    "    if (i+1) % self.model_save_step == 0:\n",
    "        G_path = os.path.join(self.model_save_dir, '{}-G_new.ckpt'.format(i+1))\n",
    "        D_path = os.path.join(self.model_save_dir, '{}-D_new.ckpt'.format(i+1))\n",
    "        torch.save(self.G.state_dict(), G_path)\n",
    "        torch.save(self.D.state_dict(), D_path)\n",
    "        with open('molgan/models/new_weights.csv', 'a') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([i+1] + list(gen_weights.detach().numpy()))\n",
    "        print('Saved model checkpoints into {}...'.format(self.model_save_dir))\n",
    "\n",
    "    # Decay learning rates.\n",
    "    if (i+1) % self.lr_update_step == 0 and (i+1) > (self.num_iters - self.num_iters_decay):\n",
    "        g_lr -= (self.g_lr / float(self.num_iters_decay))\n",
    "        d_lr -= (self.d_lr / float(self.num_iters_decay))\n",
    "        self.update_lr(g_lr, d_lr)\n",
    "        print ('Decayed learning rates, g_lr: {}, d_lr: {}.'.format(g_lr, d_lr))\n",
    "        \n",
    "    if i+1 == 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "mols, _, _, a, x, _, _, _, _ = self.data.next_train_batch(self.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_real_2 = a\n",
    "x_real_2 = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_fake = edges_hard\n",
    "x_fake = nodes_hard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For saving models\n",
    "G_path = os.path.join(self.model_save_dir, '{}-G.ckpt'.format(16923))\n",
    "D_path = os.path.join(self.model_save_dir, '{}-D.ckpt'.format(16923))\n",
    "torch.save(self.G.state_dict(), G_path)\n",
    "torch.save(self.D.state_dict(), D_path)\n",
    "with open('molgan/models/weights.csv', 'a') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([i+1] + list(gen_weights.detach().numpy()))\n",
    "print('Saved model checkpoints into {}...'.format(self.model_save_dir))\n",
    "gen_weights # 4951 [ 0.4384, -0.3454, -0.1851, -0.6287, -0.8948,  0.2568, -0.5385,  0.7215, 0.8844,  0.0439, -0.0106,  0.7786, -0.9480,  0.2930,  0.0160]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_list = [gen_circuit(gen_weights) for i in range(self.batch_size)]\n",
    "z = torch.stack(tuple(sample_list)).to(self.device).float()\n",
    "edges_logits, nodes_logits = self.G(z)\n",
    "\n",
    "(edges_hard, nodes_hard) = self.postprocess((edges_logits, nodes_logits), 'hard_gumbel')\n",
    "edges_hard, nodes_hard = torch.max(edges_hard, -1)[1], torch.max(nodes_hard, -1)[1]\n",
    "mols = [self.data.matrices2mol(n_.data.cpu().numpy(), e_.data.cpu().numpy(), strict=True)\n",
    "        for e_, n_ in zip(edges_hard, nodes_hard)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 1 1 1 0 3 3 4 3] [[0 0 2 4 0 3 3 1 2]\n",
      " [4 4 1 0 0 2 2 3 3]\n",
      " [4 1 1 3 1 2 0 4 0]\n",
      " [4 4 1 3 2 1 1 0 1]\n",
      " [2 2 3 1 1 1 2 2 1]\n",
      " [4 1 1 2 0 1 2 2 0]\n",
      " [2 4 3 1 3 2 1 4 4]\n",
      " [2 3 1 0 1 4 4 3 2]\n",
      " [3 1 0 1 2 2 3 1 4]]\n",
      "[3 0 0 1 4 1 3 3 1] [[3 0 0 1 2 2 1 4 1]\n",
      " [2 1 1 1 3 1 0 2 3]\n",
      " [3 3 3 4 2 1 3 1 3]\n",
      " [4 4 2 4 2 3 1 2 2]\n",
      " [3 3 1 2 2 1 1 3 0]\n",
      " [2 3 2 2 4 3 0 4 4]\n",
      " [0 1 2 4 1 2 4 3 2]\n",
      " [0 2 2 1 2 0 3 1 2]\n",
      " [1 3 2 1 0 4 2 3 1]]\n",
      "[3 0 2 0 4 1 4 4 3] [[2 3 0 0 1 4 4 3 4]\n",
      " [3 2 2 2 2 4 0 4 4]\n",
      " [3 1 4 4 1 4 1 1 3]\n",
      " [0 3 1 2 1 2 2 3 0]\n",
      " [3 1 2 2 2 1 2 4 2]\n",
      " [3 4 1 4 2 2 4 0 1]\n",
      " [4 4 1 2 2 2 2 1 4]\n",
      " [3 3 4 2 2 4 0 2 2]\n",
      " [4 4 3 1 2 0 0 3 3]]\n",
      "[3 1 3 0 2 3 1 2 3] [[1 0 4 0 4 4 4 4 4]\n",
      " [4 0 0 3 3 0 0 1 2]\n",
      " [0 1 4 2 3 3 2 2 0]\n",
      " [4 1 4 2 3 3 0 4 4]\n",
      " [0 4 4 4 1 1 2 3 3]\n",
      " [4 3 0 3 3 4 4 3 3]\n",
      " [3 0 3 2 2 3 3 2 2]\n",
      " [1 2 2 2 3 4 2 0 3]\n",
      " [2 1 1 3 1 1 3 2 0]]\n",
      "[4 1 4 2 3 0 4 3 4] [[1 1 4 4 1 2 0 4 2]\n",
      " [2 0 0 0 0 2 0 4 1]\n",
      " [4 1 0 1 2 2 2 4 3]\n",
      " [1 3 0 3 3 1 4 2 0]\n",
      " [3 2 3 1 4 0 3 1 0]\n",
      " [3 2 4 0 2 2 2 0 4]\n",
      " [2 2 2 4 1 3 3 2 3]\n",
      " [2 1 1 0 0 0 4 3 3]\n",
      " [0 0 0 1 1 4 1 3 2]]\n",
      "[3 0 0 4 1 0 4 3 1] [[3 4 2 3 3 4 0 0 4]\n",
      " [2 2 0 3 3 1 4 3 0]\n",
      " [3 1 3 1 1 1 2 2 1]\n",
      " [1 3 1 4 1 3 1 4 3]\n",
      " [3 4 2 3 4 1 2 1 4]\n",
      " [0 1 1 4 4 0 4 2 2]\n",
      " [1 2 1 3 1 4 1 4 0]\n",
      " [3 2 3 4 0 3 1 2 3]\n",
      " [0 3 0 3 3 1 2 4 0]]\n",
      "[1 2 2 4 0 0 3 3 0] [[4 0 3 3 4 2 3 0 4]\n",
      " [2 2 0 3 0 2 0 3 0]\n",
      " [4 1 2 2 1 0 2 0 2]\n",
      " [0 2 2 1 2 1 2 0 4]\n",
      " [3 2 0 3 4 4 1 2 2]\n",
      " [0 0 1 4 4 2 2 4 4]\n",
      " [3 2 1 1 2 3 0 2 3]\n",
      " [1 3 0 1 0 3 3 3 1]\n",
      " [2 2 3 3 3 4 4 2 4]]\n",
      "[0 2 0 3 2 3 0 3 1] [[3 3 4 1 1 1 1 3 4]\n",
      " [0 4 2 3 0 3 1 4 4]\n",
      " [4 3 1 3 2 1 3 4 1]\n",
      " [0 2 4 1 4 2 3 2 3]\n",
      " [2 2 3 0 1 3 3 1 4]\n",
      " [1 3 0 3 4 2 1 4 1]\n",
      " [3 2 3 0 0 0 0 3 1]\n",
      " [0 2 1 0 0 4 1 1 2]\n",
      " [2 3 2 1 3 2 3 0 4]]\n",
      "[0 3 4 1 1 1 0 3 2] [[0 4 4 3 1 3 1 1 2]\n",
      " [3 1 2 4 2 1 0 3 1]\n",
      " [0 1 1 0 4 1 0 2 0]\n",
      " [2 4 3 1 0 0 4 3 1]\n",
      " [4 3 0 2 4 4 3 3 0]\n",
      " [4 2 4 0 2 4 4 3 0]\n",
      " [3 2 4 1 0 1 1 1 0]\n",
      " [3 1 2 3 3 1 4 0 4]\n",
      " [0 4 0 1 0 3 2 1 3]]\n",
      "[4 4 1 1 1 3 2 3 3] [[1 1 4 2 0 4 1 3 0]\n",
      " [0 1 4 2 4 3 4 4 2]\n",
      " [3 0 4 1 1 1 4 4 2]\n",
      " [4 2 0 1 3 3 2 2 3]\n",
      " [0 4 4 4 3 3 1 2 2]\n",
      " [3 1 4 3 2 2 2 0 4]\n",
      " [3 2 0 2 1 4 3 1 2]\n",
      " [4 0 3 3 3 0 3 2 1]\n",
      " [1 4 2 1 3 1 3 4 0]]\n",
      "[2 4 2 1 0 3 3 0 3] [[1 1 3 4 4 1 4 2 0]\n",
      " [0 0 2 1 4 1 4 3 1]\n",
      " [3 4 0 4 2 4 2 3 4]\n",
      " [1 0 2 3 1 0 1 4 4]\n",
      " [3 3 3 1 1 1 1 0 3]\n",
      " [4 4 4 2 2 4 3 1 1]\n",
      " [2 2 2 3 3 4 0 0 2]\n",
      " [4 0 3 0 0 1 3 0 2]\n",
      " [2 0 2 3 3 4 4 0 3]]\n",
      "[1 0 3 4 2 3 2 2 1] [[3 0 0 1 3 4 0 1 1]\n",
      " [0 2 4 3 2 1 0 3 4]\n",
      " [3 2 2 2 0 4 3 0 3]\n",
      " [3 2 3 0 2 2 4 1 4]\n",
      " [3 3 2 0 0 2 0 1 3]\n",
      " [3 4 3 2 0 0 4 0 4]\n",
      " [2 3 2 1 4 1 2 0 4]\n",
      " [2 3 4 1 0 3 4 3 3]\n",
      " [3 0 4 2 4 3 0 3 1]]\n",
      "[1 2 2 3 0 2 1 1 3] [[0 2 4 3 2 0 3 3 3]\n",
      " [1 4 0 0 2 1 2 1 3]\n",
      " [0 2 4 4 3 0 2 0 0]\n",
      " [3 3 1 1 1 1 3 1 4]\n",
      " [4 3 3 1 4 0 2 3 0]\n",
      " [2 3 4 0 0 3 0 4 2]\n",
      " [0 0 0 3 3 2 3 1 2]\n",
      " [1 2 2 4 1 1 2 0 3]\n",
      " [0 2 4 3 1 4 1 4 0]]\n",
      "[4 0 1 4 1 3 3 2 1] [[0 0 4 2 4 0 1 0 2]\n",
      " [0 1 1 1 2 3 3 3 0]\n",
      " [0 1 2 0 1 4 3 1 2]\n",
      " [0 0 2 1 0 4 1 2 1]\n",
      " [0 0 0 2 2 0 3 4 2]\n",
      " [2 0 3 4 4 2 0 1 2]\n",
      " [3 2 4 4 3 1 4 2 4]\n",
      " [1 4 2 0 3 2 4 2 0]\n",
      " [0 2 4 2 0 0 1 2 4]]\n",
      "[4 3 0 2 0 4 0 0 2] [[2 0 3 2 4 0 1 2 1]\n",
      " [1 3 0 3 3 4 4 0 2]\n",
      " [3 4 0 0 4 3 4 2 0]\n",
      " [0 2 4 1 4 0 1 1 0]\n",
      " [3 4 0 1 4 1 4 2 1]\n",
      " [2 2 1 3 0 3 1 0 3]\n",
      " [0 4 1 4 4 2 0 4 1]\n",
      " [0 1 4 0 1 1 2 2 0]\n",
      " [4 0 4 2 3 3 0 3 3]]\n",
      "[2 3 0 0 1 2 1 4 3] [[4 3 3 3 3 0 1 1 3]\n",
      " [4 0 4 2 0 1 4 2 0]\n",
      " [3 4 2 4 0 0 0 1 3]\n",
      " [3 3 1 0 2 4 1 4 0]\n",
      " [1 2 0 4 3 1 1 4 1]\n",
      " [3 1 4 4 0 1 4 4 3]\n",
      " [3 1 3 3 2 0 2 2 1]\n",
      " [1 1 3 3 0 3 2 0 0]\n",
      " [0 0 3 2 1 3 1 4 4]]\n",
      "[0 0 3 2 3 0 0 2 3] [[4 4 3 0 4 1 3 4 1]\n",
      " [3 3 0 0 3 0 4 4 0]\n",
      " [2 0 3 2 0 0 0 0 0]\n",
      " [4 2 1 1 1 1 2 1 2]\n",
      " [3 0 0 0 2 3 0 0 0]\n",
      " [1 0 1 4 0 1 4 4 0]\n",
      " [4 3 3 3 0 2 4 4 1]\n",
      " [3 2 2 2 2 1 4 4 4]\n",
      " [1 4 1 4 0 4 0 2 2]]\n",
      "[0 1 1 3 0 0 4 4 0] [[2 3 3 2 3 2 1 2 2]\n",
      " [3 2 0 0 1 0 1 4 0]\n",
      " [4 2 3 1 1 0 3 2 4]\n",
      " [1 0 1 2 0 0 3 1 4]\n",
      " [1 2 1 3 4 2 4 3 2]\n",
      " [1 3 2 1 3 0 1 0 0]\n",
      " [3 0 1 2 1 2 0 0 3]\n",
      " [3 2 3 2 3 1 1 0 0]\n",
      " [4 3 3 0 2 2 4 3 1]]\n",
      "[3 0 4 3 0 2 1 4 1] [[2 4 2 3 0 0 4 3 2]\n",
      " [4 0 1 4 0 2 4 3 4]\n",
      " [0 2 3 3 1 0 3 3 0]\n",
      " [3 3 2 4 0 1 1 1 4]\n",
      " [3 1 1 2 4 1 1 1 2]\n",
      " [0 3 4 2 1 0 0 4 4]\n",
      " [4 2 0 4 3 3 3 3 4]\n",
      " [2 1 3 3 1 0 3 0 3]\n",
      " [4 4 4 4 4 2 4 1 1]]\n",
      "[2 3 0 0 3 4 1 3 4] [[1 4 2 2 1 0 1 2 0]\n",
      " [0 4 2 3 2 0 1 0 3]\n",
      " [1 0 0 1 3 4 0 0 1]\n",
      " [4 0 3 4 2 4 0 1 1]\n",
      " [1 0 0 3 4 3 0 2 2]\n",
      " [1 0 3 0 3 3 4 1 3]\n",
      " [0 4 0 2 0 4 0 1 4]\n",
      " [3 2 0 0 3 4 3 2 1]\n",
      " [2 1 0 0 2 4 0 3 1]]\n",
      "[0 3 3 4 1 3 4 0 0] [[4 4 2 3 2 0 2 2 2]\n",
      " [3 0 2 0 2 4 3 3 4]\n",
      " [4 2 1 3 3 0 4 4 2]\n",
      " [3 1 2 1 3 0 1 3 4]\n",
      " [0 1 4 4 2 0 4 4 1]\n",
      " [0 2 3 4 2 2 1 2 1]\n",
      " [1 4 1 2 3 2 0 0 1]\n",
      " [3 3 3 1 4 4 3 4 4]\n",
      " [2 0 4 4 1 3 1 3 3]]\n",
      "[1 0 3 1 3 2 1 4 1] [[2 3 0 3 3 0 4 4 0]\n",
      " [3 3 0 3 0 0 3 1 4]\n",
      " [0 2 0 4 3 3 1 3 2]\n",
      " [2 0 0 3 0 4 3 4 4]\n",
      " [3 4 2 1 1 2 1 2 0]\n",
      " [0 4 2 4 3 2 1 1 0]\n",
      " [1 4 0 4 1 3 0 0 3]\n",
      " [3 4 4 0 0 1 2 4 2]\n",
      " [3 3 1 3 2 0 0 0 1]]\n",
      "[1 0 1 1 0 2 4 4 2] [[2 0 3 1 3 4 2 4 4]\n",
      " [0 3 3 1 4 3 0 1 1]\n",
      " [3 3 4 3 2 1 2 3 1]\n",
      " [4 2 1 2 3 1 4 3 4]\n",
      " [1 1 1 2 1 2 0 0 2]\n",
      " [3 1 1 1 2 3 0 4 1]\n",
      " [2 0 4 4 4 1 0 4 0]\n",
      " [1 2 4 4 4 4 4 4 1]\n",
      " [1 0 4 2 3 4 2 2 3]]\n",
      "[1 0 3 0 2 1 3 2 1] [[3 1 2 0 2 1 1 3 2]\n",
      " [2 1 3 2 2 2 1 2 3]\n",
      " [3 4 3 0 3 1 4 1 2]\n",
      " [3 3 3 0 2 0 3 0 4]\n",
      " [1 2 0 1 1 0 1 1 0]\n",
      " [3 3 0 1 3 3 1 1 2]\n",
      " [0 1 1 0 4 1 4 3 3]\n",
      " [3 0 1 4 2 0 4 1 4]\n",
      " [0 0 1 2 1 4 1 1 0]]\n",
      "[2 1 1 1 0 4 4 4 0] [[2 3 4 2 2 3 3 4 2]\n",
      " [3 4 0 3 4 0 0 4 0]\n",
      " [0 4 2 0 4 3 3 4 2]\n",
      " [0 1 1 1 0 4 0 4 2]\n",
      " [2 1 3 4 3 3 3 3 0]\n",
      " [2 2 3 1 3 1 1 0 4]\n",
      " [4 1 3 0 4 1 3 1 2]\n",
      " [2 1 0 3 4 4 1 1 3]\n",
      " [4 3 0 0 3 1 3 4 4]]\n",
      "[4 3 2 4 2 1 1 1 4] [[2 2 4 2 1 4 3 4 1]\n",
      " [1 4 2 2 3 1 0 1 3]\n",
      " [0 1 2 0 1 1 1 2 2]\n",
      " [3 4 1 2 4 3 4 4 3]\n",
      " [2 4 1 2 3 0 1 4 2]\n",
      " [4 4 0 4 2 2 4 0 3]\n",
      " [2 0 1 3 0 2 4 4 4]\n",
      " [3 3 3 0 3 1 1 0 3]\n",
      " [2 0 3 0 1 2 2 4 0]]\n",
      "[1 1 4 2 0 3 2 2 1] [[1 4 4 0 1 0 2 1 3]\n",
      " [3 2 4 4 4 4 2 1 4]\n",
      " [1 2 1 4 0 3 0 0 2]\n",
      " [2 4 1 3 3 4 3 0 3]\n",
      " [1 4 0 0 3 2 1 0 1]\n",
      " [0 4 4 3 2 2 4 1 1]\n",
      " [1 3 1 3 4 2 1 4 2]\n",
      " [4 3 1 2 3 2 3 2 1]\n",
      " [4 3 3 4 2 0 2 1 0]]\n",
      "[4 0 2 0 1 0 1 1 3] [[3 4 4 2 0 4 4 3 0]\n",
      " [4 2 0 4 0 1 2 2 3]\n",
      " [4 3 0 4 4 2 1 4 4]\n",
      " [4 3 0 1 0 2 1 3 1]\n",
      " [3 0 3 1 4 2 3 0 3]\n",
      " [1 0 1 2 2 3 1 0 2]\n",
      " [3 2 0 3 1 0 2 3 3]\n",
      " [0 3 1 1 1 0 3 2 0]\n",
      " [3 2 3 4 4 4 0 3 0]]\n",
      "[3 1 2 3 1 3 0 0 0] [[1 4 3 3 2 4 1 3 0]\n",
      " [2 1 0 1 0 4 1 4 1]\n",
      " [3 2 3 1 4 1 1 2 2]\n",
      " [3 3 2 4 4 2 4 2 4]\n",
      " [3 2 0 2 1 4 3 1 3]\n",
      " [2 1 0 0 0 2 0 4 2]\n",
      " [3 1 0 1 2 2 4 1 1]\n",
      " [4 4 1 2 4 3 3 0 3]\n",
      " [3 2 0 1 2 4 4 2 2]]\n",
      "[2 2 0 3 4 0 0 0 0] [[1 2 3 3 2 4 1 2 4]\n",
      " [4 1 0 0 4 0 2 1 4]\n",
      " [3 1 1 1 1 2 3 0 3]\n",
      " [2 0 0 1 4 4 0 1 2]\n",
      " [2 1 2 0 2 4 2 0 1]\n",
      " [2 3 2 2 1 0 1 0 1]\n",
      " [0 2 2 2 4 3 0 0 2]\n",
      " [1 3 4 3 2 3 4 1 2]\n",
      " [4 0 0 2 2 2 0 2 0]]\n",
      "[4 2 3 4 0 0 4 1 1] [[2 1 0 3 0 2 2 4 1]\n",
      " [1 1 0 0 2 4 0 0 4]\n",
      " [3 2 3 4 3 4 2 1 2]\n",
      " [4 1 0 4 1 0 3 2 3]\n",
      " [0 3 4 4 3 0 1 3 1]\n",
      " [4 3 1 3 0 3 4 4 1]\n",
      " [4 3 4 0 2 1 4 1 2]\n",
      " [1 3 2 2 4 2 2 0 3]\n",
      " [3 2 4 1 0 4 4 3 0]]\n",
      "[2 1 2 2 0 0 2 3 0] [[2 2 3 0 2 1 3 4 0]\n",
      " [3 1 4 0 4 4 4 0 3]\n",
      " [2 2 4 2 0 1 4 3 1]\n",
      " [1 2 2 3 0 2 4 0 2]\n",
      " [4 1 2 0 0 0 1 3 2]\n",
      " [1 2 3 1 3 4 2 1 2]\n",
      " [4 3 1 4 0 2 4 2 2]\n",
      " [1 4 3 2 1 4 1 0 2]\n",
      " [3 0 1 4 2 4 3 3 1]]\n",
      "[4 4 3 1 0 2 4 1 3] [[1 0 0 2 4 3 0 2 3]\n",
      " [0 4 2 2 1 4 2 3 3]\n",
      " [2 3 1 4 2 3 0 0 1]\n",
      " [4 0 2 2 1 0 4 4 2]\n",
      " [0 0 4 0 3 4 3 2 4]\n",
      " [4 3 4 1 1 3 1 3 4]\n",
      " [2 1 4 3 3 3 4 3 3]\n",
      " [2 0 0 4 2 0 1 0 2]\n",
      " [4 4 2 3 3 1 2 2 0]]\n",
      "[2 0 2 3 2 1 1 3 2] [[3 2 0 1 0 2 4 4 1]\n",
      " [3 0 1 0 1 1 3 2 4]\n",
      " [4 4 3 2 3 3 1 0 3]\n",
      " [1 0 2 2 3 0 4 4 1]\n",
      " [2 1 3 0 4 4 3 0 2]\n",
      " [2 1 2 4 4 1 1 2 0]\n",
      " [4 0 3 2 4 1 3 3 0]\n",
      " [4 0 3 1 4 2 0 4 1]\n",
      " [1 3 3 1 3 2 0 2 0]]\n",
      "[4 2 4 1 4 3 4 1 1] [[0 2 1 3 1 0 3 2 2]\n",
      " [3 0 1 2 2 3 1 3 1]\n",
      " [3 3 3 0 0 3 4 3 2]\n",
      " [2 3 0 4 2 0 0 0 2]\n",
      " [2 1 1 0 1 3 3 4 2]\n",
      " [3 0 3 0 0 4 0 4 1]\n",
      " [3 2 1 4 0 0 0 0 0]\n",
      " [2 4 4 1 3 1 2 0 4]\n",
      " [2 2 2 2 3 4 4 1 1]]\n",
      "[2 3 3 0 3 3 1 4 0] [[3 0 0 2 2 0 1 3 4]\n",
      " [0 4 2 0 4 0 4 1 2]\n",
      " [3 0 4 0 3 4 3 3 0]\n",
      " [4 1 0 0 0 0 4 2 0]\n",
      " [2 0 0 2 1 3 2 3 3]\n",
      " [1 3 0 4 3 3 2 2 1]\n",
      " [0 1 1 0 3 3 4 3 4]\n",
      " [0 1 2 0 3 1 2 2 2]\n",
      " [3 1 2 3 1 2 1 3 0]]\n",
      "[2 2 0 1 0 4 1 4 4] [[3 1 1 0 1 3 1 3 3]\n",
      " [1 3 4 3 3 3 2 4 0]\n",
      " [2 1 1 2 2 1 4 3 3]\n",
      " [1 4 4 4 2 3 0 2 1]\n",
      " [2 3 0 1 2 2 2 3 2]\n",
      " [3 2 0 1 2 2 4 2 1]\n",
      " [0 4 3 3 1 0 0 4 1]\n",
      " [3 0 4 1 1 2 4 2 2]\n",
      " [2 1 3 4 0 2 1 0 2]]\n",
      "[2 4 2 1 0 4 4 1 1] [[0 0 4 1 3 3 3 1 3]\n",
      " [2 2 4 4 4 2 3 1 3]\n",
      " [0 4 1 0 2 3 0 3 4]\n",
      " [1 1 2 0 0 4 1 3 3]\n",
      " [3 4 3 1 4 2 3 2 0]\n",
      " [4 2 2 0 2 0 0 1 4]\n",
      " [3 2 4 3 4 0 1 2 1]\n",
      " [0 1 2 2 2 4 2 4 3]\n",
      " [4 4 0 0 1 4 3 3 1]]\n",
      "[1 0 1 1 1 0 2 1 0] [[0 0 2 1 4 1 3 3 0]\n",
      " [3 1 4 1 3 3 2 2 4]\n",
      " [4 0 3 3 4 2 3 4 4]\n",
      " [0 3 3 4 2 3 1 1 4]\n",
      " [0 0 2 1 2 0 2 0 1]\n",
      " [0 0 2 0 4 4 4 2 4]\n",
      " [3 3 4 3 2 3 0 3 3]\n",
      " [1 1 0 2 0 2 0 4 4]\n",
      " [4 0 4 4 0 0 0 2 3]]\n",
      "[4 3 3 2 2 1 3 3 3] [[4 4 4 0 2 2 2 1 0]\n",
      " [3 1 3 0 2 4 4 1 3]\n",
      " [2 2 1 2 3 0 1 3 1]\n",
      " [4 2 1 1 3 3 0 3 0]\n",
      " [0 4 1 2 1 0 4 3 2]\n",
      " [3 1 2 0 1 3 3 1 2]\n",
      " [1 1 3 2 1 0 4 0 3]\n",
      " [2 3 0 1 0 4 0 3 3]\n",
      " [1 4 2 3 0 3 0 3 3]]\n",
      "[3 4 1 3 4 4 0 1 3] [[1 1 4 4 2 0 2 0 0]\n",
      " [4 3 2 1 0 4 2 4 4]\n",
      " [2 4 0 2 0 2 1 0 1]\n",
      " [4 3 1 1 1 0 1 1 1]\n",
      " [2 3 0 2 0 0 3 2 0]\n",
      " [4 4 2 4 2 2 4 3 3]\n",
      " [3 4 4 0 3 4 3 2 2]\n",
      " [4 0 1 2 1 3 3 2 1]\n",
      " [0 4 2 1 2 2 2 1 1]]\n",
      "[3 1 4 1 2 2 2 2 2] [[4 2 3 0 3 0 4 3 1]\n",
      " [1 4 2 0 2 2 0 3 0]\n",
      " [3 4 2 0 0 1 0 1 3]\n",
      " [1 3 1 2 3 3 1 3 3]\n",
      " [2 1 0 3 1 3 4 0 3]\n",
      " [1 4 1 1 1 1 1 0 2]\n",
      " [3 3 2 1 3 4 2 0 2]\n",
      " [3 3 1 4 1 4 3 4 3]\n",
      " [0 3 2 0 1 0 1 1 2]]\n",
      "[0 0 1 2 1 3 2 0 0] [[0 1 4 0 3 1 4 1 1]\n",
      " [3 3 2 3 2 1 4 0 3]\n",
      " [1 4 2 4 0 1 4 0 1]\n",
      " [0 4 4 3 1 3 3 3 4]\n",
      " [1 1 2 0 3 3 0 1 2]\n",
      " [1 4 3 2 0 0 2 1 1]\n",
      " [4 3 4 3 0 1 4 3 3]\n",
      " [2 1 0 3 4 3 2 2 0]\n",
      " [4 0 4 3 3 0 3 2 3]]\n",
      "[4 3 3 0 2 1 1 1 0] [[0 2 0 1 1 3 4 0 1]\n",
      " [4 4 4 1 0 3 4 1 1]\n",
      " [4 0 3 2 4 0 4 1 2]\n",
      " [4 0 3 2 0 3 0 1 2]\n",
      " [0 4 0 4 4 1 3 3 3]\n",
      " [2 2 3 3 3 0 3 1 4]\n",
      " [3 0 0 2 1 4 4 0 4]\n",
      " [4 4 3 3 4 2 1 2 1]\n",
      " [3 4 0 3 2 4 0 4 2]]\n",
      "[3 2 3 0 4 0 3 1 1] [[2 2 2 4 3 3 0 0 4]\n",
      " [3 2 0 0 2 0 0 1 0]\n",
      " [0 1 1 2 1 1 4 2 2]\n",
      " [1 3 0 3 4 2 3 1 2]\n",
      " [1 3 4 3 0 0 4 0 4]\n",
      " [1 4 2 3 3 2 0 4 1]\n",
      " [4 1 2 3 3 0 0 2 2]\n",
      " [1 0 0 2 0 4 0 3 4]\n",
      " [2 1 1 3 1 0 0 4 1]]\n",
      "[3 0 2 2 3 1 4 4 1] [[4 4 0 4 1 2 3 0 0]\n",
      " [1 2 3 0 2 3 4 1 2]\n",
      " [2 0 1 1 2 0 2 1 1]\n",
      " [1 2 4 4 3 3 0 2 1]\n",
      " [4 1 4 3 0 3 2 0 2]\n",
      " [4 1 2 3 1 1 1 1 0]\n",
      " [1 4 3 1 0 2 3 1 1]\n",
      " [3 0 4 1 3 1 2 1 3]\n",
      " [4 2 3 3 1 1 2 1 2]]\n",
      "[2 1 2 2 4 3 4 2 3] [[1 4 3 1 1 3 4 4 2]\n",
      " [2 4 3 3 2 4 2 2 2]\n",
      " [0 1 0 3 1 1 0 0 1]\n",
      " [3 0 2 3 0 4 1 2 3]\n",
      " [2 4 2 0 4 3 0 1 2]\n",
      " [2 1 1 2 4 4 2 2 2]\n",
      " [4 0 2 1 0 2 0 1 4]\n",
      " [2 1 4 1 4 1 2 3 3]\n",
      " [4 2 4 1 2 0 3 4 4]]\n",
      "[1 4 0 3 0 2 2 3 1] [[1 3 3 4 0 0 1 0 4]\n",
      " [1 3 4 4 3 1 4 0 1]\n",
      " [3 1 0 4 0 2 2 2 2]\n",
      " [1 3 1 2 3 2 1 3 0]\n",
      " [3 2 2 1 4 4 2 3 3]\n",
      " [1 3 2 0 1 4 0 0 3]\n",
      " [1 0 1 2 1 4 0 4 2]\n",
      " [2 0 2 1 0 2 0 1 4]\n",
      " [4 3 3 4 2 3 3 0 3]]\n",
      "[0 4 4 2 4 0 4 1 0] [[1 3 2 4 1 1 4 3 3]\n",
      " [0 4 3 2 0 4 3 2 4]\n",
      " [4 1 4 3 4 2 1 2 2]\n",
      " [1 2 1 0 2 3 4 4 0]\n",
      " [0 1 1 1 3 3 1 4 4]\n",
      " [3 2 1 1 4 0 0 3 1]\n",
      " [3 2 4 1 1 0 3 2 0]\n",
      " [0 1 0 3 0 3 1 4 2]\n",
      " [1 3 3 0 1 0 4 3 3]]\n",
      "[1 1 3 4 2 0 3 1 4] [[1 2 4 3 0 1 1 3 4]\n",
      " [4 2 3 0 2 4 1 0 2]\n",
      " [1 0 4 3 0 1 3 1 2]\n",
      " [4 2 3 4 4 1 4 0 4]\n",
      " [2 2 4 4 1 4 4 4 4]\n",
      " [1 2 1 1 0 1 1 0 4]\n",
      " [3 0 3 4 1 4 3 1 4]\n",
      " [4 0 2 1 4 4 1 4 3]\n",
      " [1 1 0 0 3 2 4 4 2]]\n",
      "[2 3 1 3 2 0 4 1 3] [[4 3 2 1 2 1 2 2 1]\n",
      " [1 3 3 0 1 0 3 2 3]\n",
      " [2 4 1 3 4 0 4 1 2]\n",
      " [4 4 0 1 4 2 4 3 0]\n",
      " [4 1 0 3 2 0 2 0 3]\n",
      " [3 3 0 2 1 1 1 2 4]\n",
      " [2 1 4 2 3 2 1 3 1]\n",
      " [3 4 4 1 0 2 4 0 3]\n",
      " [1 1 0 2 0 1 1 3 3]]\n",
      "[2 0 3 4 4 0 2 1 4] [[2 4 2 1 2 0 2 3 1]\n",
      " [3 2 3 0 1 3 1 3 1]\n",
      " [1 4 2 0 3 2 3 4 3]\n",
      " [4 1 2 3 1 3 3 3 1]\n",
      " [0 3 0 1 3 3 1 3 4]\n",
      " [3 2 2 4 0 1 1 1 3]\n",
      " [3 4 0 4 2 1 4 3 0]\n",
      " [3 4 1 0 4 4 0 0 0]\n",
      " [4 0 2 0 3 3 0 4 4]]\n",
      "[4 0 1 1 1 4 3 4 0] [[0 0 0 1 1 0 0 3 3]\n",
      " [0 0 0 0 2 0 4 0 3]\n",
      " [4 3 3 2 4 0 3 1 3]\n",
      " [0 3 3 1 1 4 0 4 0]\n",
      " [3 4 2 3 3 0 4 0 4]\n",
      " [2 0 2 2 1 1 2 1 0]\n",
      " [3 1 2 3 0 2 2 4 4]\n",
      " [0 4 4 1 0 4 0 2 3]\n",
      " [0 4 1 3 2 0 4 1 3]]\n",
      "[4 3 1 0 2 3 3 2 3] [[3 1 2 2 4 1 0 2 3]\n",
      " [1 2 0 0 2 3 2 4 1]\n",
      " [1 4 0 1 0 4 4 4 2]\n",
      " [3 0 2 4 3 4 0 4 0]\n",
      " [2 3 0 3 1 0 1 0 0]\n",
      " [1 4 2 3 4 3 3 1 4]\n",
      " [1 4 2 0 1 1 1 3 3]\n",
      " [3 3 0 3 4 4 2 1 1]\n",
      " [1 1 4 3 4 3 0 1 1]]\n",
      "[0 3 4 4 2 4 1 4 4] [[1 4 1 4 2 4 2 0 4]\n",
      " [4 3 0 4 3 1 4 4 0]\n",
      " [3 3 3 4 0 4 2 1 3]\n",
      " [3 1 1 0 3 3 3 2 1]\n",
      " [0 3 0 2 2 0 2 0 1]\n",
      " [4 4 1 2 3 4 1 0 0]\n",
      " [3 3 0 0 3 3 0 3 1]\n",
      " [4 2 1 3 3 1 2 1 0]\n",
      " [0 2 2 2 4 0 3 0 0]]\n",
      "[2 1 3 3 0 3 3 0 3] [[1 2 3 0 2 2 0 2 3]\n",
      " [4 2 4 0 1 0 4 4 3]\n",
      " [2 4 4 0 0 2 3 0 0]\n",
      " [1 4 4 3 4 4 4 1 1]\n",
      " [4 3 0 1 2 0 1 3 2]\n",
      " [4 2 4 2 3 4 3 3 4]\n",
      " [3 3 2 0 2 4 0 3 2]\n",
      " [1 4 3 0 4 1 0 4 2]\n",
      " [1 1 2 2 3 4 0 1 3]]\n",
      "[4 0 1 0 1 4 4 1 3] [[2 0 3 1 1 3 0 2 4]\n",
      " [4 3 3 4 4 1 2 4 0]\n",
      " [1 1 2 3 0 2 0 1 2]\n",
      " [2 1 0 2 0 3 4 3 1]\n",
      " [2 4 3 0 0 1 0 3 1]\n",
      " [0 0 0 4 0 4 3 3 3]\n",
      " [3 1 3 4 1 4 3 4 0]\n",
      " [1 0 2 2 0 4 4 3 1]\n",
      " [0 2 0 0 1 1 4 1 0]]\n",
      "[1 4 3 1 4 0 0 1 3] [[0 3 0 0 2 3 4 1 4]\n",
      " [4 3 4 0 2 3 3 4 2]\n",
      " [4 0 1 0 2 0 3 0 3]\n",
      " [2 1 4 3 3 4 3 4 1]\n",
      " [2 0 0 1 1 3 0 0 3]\n",
      " [0 1 4 0 0 0 0 0 2]\n",
      " [1 4 1 3 1 3 1 2 2]\n",
      " [3 4 1 3 4 0 4 0 4]\n",
      " [3 3 4 1 3 0 1 4 2]]\n",
      "[1 3 4 4 3 2 0 3 3] [[2 1 0 2 2 4 0 4 1]\n",
      " [3 2 1 1 3 0 4 0 4]\n",
      " [3 2 0 2 2 1 3 1 3]\n",
      " [1 0 2 1 3 4 2 3 0]\n",
      " [3 4 3 0 3 0 1 2 1]\n",
      " [2 2 2 1 4 4 0 4 4]\n",
      " [2 1 0 4 2 4 3 0 2]\n",
      " [4 2 1 2 2 1 2 4 3]\n",
      " [4 3 4 4 0 0 3 3 2]]\n",
      "[1 2 1 0 1 2 1 4 2] [[3 4 4 1 2 4 4 3 3]\n",
      " [0 4 0 4 0 4 3 3 2]\n",
      " [2 1 1 2 4 4 1 2 1]\n",
      " [0 0 1 2 1 3 3 4 4]\n",
      " [2 3 1 1 1 0 1 4 2]\n",
      " [2 2 0 1 0 0 1 2 1]\n",
      " [1 2 1 4 2 1 2 2 3]\n",
      " [0 4 4 3 0 0 4 0 2]\n",
      " [4 2 3 0 4 1 0 3 3]]\n",
      "[2 0 0 3 4 1 1 4 4] [[0 4 1 0 3 4 4 4 4]\n",
      " [2 2 1 2 2 1 2 2 0]\n",
      " [0 3 0 0 0 4 1 1 2]\n",
      " [2 2 4 0 2 4 1 2 2]\n",
      " [0 4 4 2 2 2 1 3 1]\n",
      " [1 3 4 1 3 4 1 4 4]\n",
      " [0 4 2 3 2 4 2 4 3]\n",
      " [0 3 3 0 0 1 3 2 1]\n",
      " [0 1 3 1 4 2 1 4 3]]\n",
      "[4 4 4 4 3 4 0 0 0] [[3 1 1 1 2 1 4 4 2]\n",
      " [3 2 1 0 2 3 1 1 1]\n",
      " [0 4 0 3 1 3 0 1 0]\n",
      " [2 3 4 3 0 0 0 3 1]\n",
      " [0 3 2 1 0 3 4 4 0]\n",
      " [1 1 2 1 4 4 2 0 3]\n",
      " [0 1 2 4 4 3 2 3 2]\n",
      " [4 3 0 2 2 0 0 1 1]\n",
      " [1 1 1 0 3 2 0 1 4]]\n",
      "[2 1 3 0 1 2 1 1 4] [[4 0 1 2 3 1 2 4 4]\n",
      " [3 1 4 1 0 0 4 0 3]\n",
      " [2 1 4 4 0 1 3 4 1]\n",
      " [4 4 0 4 1 0 2 1 0]\n",
      " [2 3 0 3 0 1 0 0 3]\n",
      " [2 0 0 1 3 3 3 3 4]\n",
      " [3 4 4 1 2 0 4 3 3]\n",
      " [4 1 2 1 0 3 1 2 1]\n",
      " [0 0 4 4 0 2 4 1 4]]\n",
      "[0 2 1 1 2 3 3 3 0] [[4 4 3 0 0 1 3 3 1]\n",
      " [3 2 4 3 4 4 4 4 1]\n",
      " [3 2 0 4 0 3 1 2 1]\n",
      " [3 1 4 3 1 0 0 3 2]\n",
      " [0 0 1 4 1 0 4 2 0]\n",
      " [3 3 4 2 1 0 0 3 0]\n",
      " [1 2 3 2 1 4 1 3 4]\n",
      " [4 1 0 1 4 1 4 0 1]\n",
      " [1 1 4 1 2 3 2 3 2]]\n",
      "[1 3 0 4 1 3 3 3 4] [[3 4 1 3 3 0 2 4 1]\n",
      " [1 4 4 0 3 2 1 2 3]\n",
      " [2 4 4 2 0 2 3 4 2]\n",
      " [2 4 0 0 3 0 1 3 2]\n",
      " [3 2 2 3 1 2 0 3 1]\n",
      " [4 2 0 3 0 0 0 0 2]\n",
      " [1 4 3 4 2 0 1 1 1]\n",
      " [4 1 0 0 0 0 0 1 0]\n",
      " [2 3 1 1 0 1 0 2 3]]\n",
      "[0 0 4 4 4 4 3 1 0] [[2 4 0 0 3 4 4 3 4]\n",
      " [2 4 0 1 2 4 0 0 1]\n",
      " [3 4 2 0 3 3 4 3 2]\n",
      " [0 3 4 2 2 2 0 0 4]\n",
      " [1 3 4 1 2 2 4 4 3]\n",
      " [3 4 4 1 0 3 4 0 4]\n",
      " [0 1 4 3 3 1 1 1 2]\n",
      " [1 1 3 4 1 2 0 0 3]\n",
      " [3 2 2 3 1 3 3 4 4]]\n",
      "[3 1 1 1 0 3 1 1 4] [[0 0 0 2 1 1 2 2 1]\n",
      " [0 3 4 0 2 1 3 3 4]\n",
      " [1 3 0 4 0 0 0 2 1]\n",
      " [4 1 1 2 2 2 2 2 2]\n",
      " [0 4 4 0 4 4 0 2 2]\n",
      " [0 0 3 2 2 1 4 3 2]\n",
      " [0 0 0 3 0 2 4 2 0]\n",
      " [3 4 3 0 0 2 4 1 1]\n",
      " [3 0 2 2 0 4 0 2 2]]\n",
      "[0 0 1 0 3 1 2 3 2] [[0 1 1 3 4 3 3 0 0]\n",
      " [3 1 3 4 0 3 1 2 0]\n",
      " [3 4 0 0 2 0 1 4 1]\n",
      " [2 1 0 1 2 3 0 3 3]\n",
      " [0 2 4 3 4 4 0 0 2]\n",
      " [4 1 2 3 3 4 0 4 3]\n",
      " [4 0 0 4 4 4 1 3 1]\n",
      " [4 0 1 2 0 3 1 0 2]\n",
      " [4 4 4 2 1 0 4 1 3]]\n",
      "[0 2 0 1 4 2 0 0 1] [[1 3 2 3 3 4 0 1 2]\n",
      " [1 1 0 2 4 2 1 0 4]\n",
      " [3 2 0 0 3 1 2 0 4]\n",
      " [2 2 2 2 1 1 4 3 4]\n",
      " [3 1 4 2 3 3 0 4 2]\n",
      " [3 3 2 0 3 4 2 3 3]\n",
      " [0 0 3 3 0 4 4 4 2]\n",
      " [1 0 4 3 3 2 4 0 2]\n",
      " [2 3 0 0 3 2 1 2 4]]\n",
      "[2 0 4 2 0 0 3 2 3] [[2 3 0 2 1 0 1 0 2]\n",
      " [0 3 3 1 3 4 1 0 3]\n",
      " [0 1 4 2 3 2 1 2 1]\n",
      " [0 0 3 2 3 1 2 4 4]\n",
      " [1 3 0 1 4 2 4 4 1]\n",
      " [3 1 4 4 2 1 4 0 2]\n",
      " [2 0 4 4 0 1 0 0 4]\n",
      " [3 2 0 3 0 4 2 2 3]\n",
      " [4 1 0 4 0 3 2 1 4]]\n",
      "[0 2 2 1 4 3 2 4 0] [[1 1 1 1 3 3 4 3 2]\n",
      " [1 2 0 0 0 2 1 0 1]\n",
      " [0 3 0 4 0 4 3 4 2]\n",
      " [4 3 2 2 1 4 4 0 4]\n",
      " [4 1 2 0 0 4 2 4 1]\n",
      " [4 1 4 1 0 3 4 0 1]\n",
      " [2 4 0 3 0 3 4 2 2]\n",
      " [0 1 1 2 3 2 1 0 2]\n",
      " [0 1 4 4 3 3 0 4 0]]\n",
      "[2 3 0 4 1 1 0 0 0] [[2 1 0 0 1 2 0 1 0]\n",
      " [0 3 3 1 0 0 1 3 4]\n",
      " [3 2 4 2 4 4 0 3 0]\n",
      " [4 4 3 1 0 1 2 2 0]\n",
      " [2 1 4 2 0 2 3 1 4]\n",
      " [4 1 4 0 2 0 0 3 2]\n",
      " [0 0 3 0 4 1 0 4 4]\n",
      " [3 0 0 2 0 2 1 4 4]\n",
      " [2 4 1 3 3 4 4 3 0]]\n",
      "[3 4 3 4 3 1 1 1 1] [[1 3 0 0 2 1 2 4 1]\n",
      " [2 3 4 2 3 1 2 4 4]\n",
      " [1 4 2 4 2 2 2 2 2]\n",
      " [3 3 0 4 1 1 1 1 2]\n",
      " [3 1 0 4 3 1 1 3 1]\n",
      " [1 4 4 3 3 4 3 2 0]\n",
      " [2 3 0 1 4 4 2 2 0]\n",
      " [3 0 0 2 2 0 3 0 0]\n",
      " [4 0 4 4 4 0 2 1 2]]\n",
      "[2 0 2 2 0 1 0 0 4] [[2 0 3 0 3 4 0 1 2]\n",
      " [0 2 4 1 4 4 3 3 3]\n",
      " [4 1 3 3 2 3 2 1 0]\n",
      " [1 3 4 2 2 3 2 1 1]\n",
      " [1 4 4 4 3 1 2 4 1]\n",
      " [0 3 0 3 0 1 3 4 1]\n",
      " [2 1 2 0 3 2 0 4 3]\n",
      " [2 2 0 3 3 0 2 0 0]\n",
      " [0 0 2 1 1 0 0 1 3]]\n",
      "[1 1 1 1 1 3 2 1 1] [[2 0 3 0 1 1 4 3 3]\n",
      " [2 2 0 3 1 3 4 2 3]\n",
      " [1 0 4 0 2 3 1 3 2]\n",
      " [0 2 4 3 1 3 1 2 0]\n",
      " [3 3 3 2 4 4 0 0 3]\n",
      " [0 2 0 4 1 2 4 0 0]\n",
      " [4 1 2 4 0 3 2 2 2]\n",
      " [0 3 2 0 3 2 0 0 2]\n",
      " [4 0 1 0 3 4 0 2 4]]\n",
      "[2 3 3 2 1 3 3 0 0] [[1 2 0 0 0 2 2 2 1]\n",
      " [0 3 2 2 1 4 2 3 3]\n",
      " [0 1 1 4 2 2 1 2 2]\n",
      " [4 4 0 4 4 0 0 1 4]\n",
      " [2 2 0 1 4 0 2 4 2]\n",
      " [2 3 1 4 3 3 2 0 4]\n",
      " [1 4 1 3 4 2 1 2 3]\n",
      " [2 2 2 2 0 3 0 4 1]\n",
      " [3 4 3 4 2 2 4 2 1]]\n",
      "[0 2 2 1 2 1 0 0 2] [[2 3 2 3 3 1 4 3 1]\n",
      " [2 0 4 1 4 0 3 0 2]\n",
      " [1 2 2 1 2 3 0 4 4]\n",
      " [1 0 3 0 4 3 3 0 0]\n",
      " [1 2 2 0 3 4 1 0 2]\n",
      " [2 3 4 4 0 3 3 1 2]\n",
      " [3 1 0 4 3 0 3 1 2]\n",
      " [1 2 4 0 4 0 2 3 4]\n",
      " [3 3 0 0 1 4 1 3 0]]\n",
      "[3 2 0 0 1 2 4 1 0] [[1 0 1 4 2 3 3 4 3]\n",
      " [4 2 2 3 1 1 1 4 1]\n",
      " [4 0 1 4 4 4 1 2 4]\n",
      " [2 1 3 4 0 0 3 0 3]\n",
      " [2 1 2 0 1 3 3 3 2]\n",
      " [0 0 0 3 1 4 2 0 1]\n",
      " [3 1 0 4 0 4 0 2 1]\n",
      " [1 3 1 4 0 4 2 2 1]\n",
      " [2 0 0 4 2 3 0 0 2]]\n",
      "[3 3 2 3 2 4 3 0 1] [[0 3 0 1 2 1 2 1 3]\n",
      " [2 3 4 4 1 1 1 3 1]\n",
      " [0 4 1 3 4 1 3 0 2]\n",
      " [4 4 0 0 1 1 4 4 3]\n",
      " [1 0 4 0 4 3 2 4 0]\n",
      " [3 3 3 1 1 1 0 3 2]\n",
      " [4 1 4 3 2 2 2 0 4]\n",
      " [3 2 4 0 1 2 3 4 2]\n",
      " [2 3 0 3 4 4 1 4 3]]\n",
      "[1 1 2 3 0 1 1 0 4] [[3 2 3 0 3 3 0 4 0]\n",
      " [2 4 4 3 4 3 3 2 1]\n",
      " [2 4 1 2 2 2 2 3 3]\n",
      " [2 1 2 1 1 0 3 4 0]\n",
      " [0 4 2 0 0 4 1 2 1]\n",
      " [2 4 3 2 4 0 2 1 3]\n",
      " [3 1 0 4 1 4 3 2 4]\n",
      " [0 3 3 4 2 4 3 4 1]\n",
      " [3 0 1 3 1 1 0 3 2]]\n",
      "[0 4 0 2 0 3 3 0 0] [[2 3 1 1 3 4 0 3 2]\n",
      " [2 1 1 4 3 0 0 4 4]\n",
      " [0 4 3 1 3 2 1 4 4]\n",
      " [3 3 0 1 0 3 4 1 1]\n",
      " [3 0 4 4 2 0 0 1 4]\n",
      " [2 4 4 3 2 1 4 1 1]\n",
      " [1 2 2 4 4 2 2 4 3]\n",
      " [1 2 2 2 1 2 1 2 0]\n",
      " [1 3 0 3 1 3 0 0 0]]\n",
      "[4 1 1 1 0 4 0 0 1] [[2 4 1 0 2 4 1 1 4]\n",
      " [3 1 2 0 1 1 2 4 3]\n",
      " [3 3 2 4 0 0 4 2 0]\n",
      " [1 2 0 4 1 2 0 2 3]\n",
      " [3 3 2 3 3 0 3 4 1]\n",
      " [0 3 2 4 2 0 0 2 3]\n",
      " [4 0 0 3 2 0 4 3 0]\n",
      " [3 3 2 1 3 4 4 4 0]\n",
      " [0 4 2 1 1 4 0 4 0]]\n",
      "[4 4 1 1 3 4 3 2 1] [[1 1 3 2 4 3 4 2 4]\n",
      " [2 3 3 4 4 4 1 0 2]\n",
      " [2 2 0 3 0 0 4 3 3]\n",
      " [2 2 1 2 3 2 0 3 3]\n",
      " [1 1 4 2 0 3 1 4 3]\n",
      " [1 0 1 1 3 1 1 0 1]\n",
      " [3 1 1 3 0 2 1 3 1]\n",
      " [1 3 0 2 2 2 0 4 4]\n",
      " [1 1 2 0 1 0 4 1 4]]\n",
      "[0 1 0 4 4 4 0 2 0] [[0 1 3 1 4 2 0 2 1]\n",
      " [0 4 4 4 0 1 2 3 1]\n",
      " [0 2 1 1 0 0 4 2 2]\n",
      " [0 1 3 0 2 4 2 1 0]\n",
      " [3 2 1 3 2 4 3 0 0]\n",
      " [2 4 3 2 2 3 3 2 3]\n",
      " [0 1 0 4 3 2 1 0 1]\n",
      " [1 1 4 0 1 2 2 3 2]\n",
      " [3 0 4 3 3 2 4 2 0]]\n",
      "[0 0 2 1 3 2 3 4 3] [[1 2 3 3 4 0 3 1 4]\n",
      " [3 0 0 3 2 3 1 2 0]\n",
      " [4 0 2 4 3 0 4 4 1]\n",
      " [4 4 0 2 0 3 2 2 3]\n",
      " [1 3 2 4 0 1 0 4 2]\n",
      " [2 4 2 4 1 0 3 1 2]\n",
      " [0 0 2 3 4 1 3 1 1]\n",
      " [3 4 2 2 0 0 4 2 2]\n",
      " [4 1 1 1 1 1 2 2 0]]\n",
      "[2 3 1 1 4 4 0 4 3] [[1 0 2 4 3 1 1 1 0]\n",
      " [3 1 0 3 0 3 2 4 2]\n",
      " [0 1 0 1 2 0 2 1 0]\n",
      " [4 1 2 3 2 2 4 2 1]\n",
      " [3 4 0 3 3 2 4 4 3]\n",
      " [2 0 1 2 3 0 2 0 1]\n",
      " [3 1 3 3 3 1 4 0 3]\n",
      " [2 2 3 4 0 0 2 4 1]\n",
      " [1 4 1 0 3 3 2 4 4]]\n",
      "[0 3 3 0 2 4 1 1 3] [[2 2 3 4 1 1 1 4 1]\n",
      " [2 4 0 0 0 1 0 4 1]\n",
      " [1 1 2 4 0 2 2 0 0]\n",
      " [3 4 3 2 2 2 0 3 2]\n",
      " [0 1 0 2 3 4 1 1 3]\n",
      " [2 1 3 2 0 1 2 3 0]\n",
      " [4 0 0 1 0 4 2 4 0]\n",
      " [2 1 4 4 4 1 3 1 0]\n",
      " [1 4 3 2 3 0 3 2 1]]\n",
      "[3 3 4 1 1 1 3 4 4] [[1 0 4 1 4 3 4 3 2]\n",
      " [0 0 0 3 4 4 2 0 4]\n",
      " [0 0 4 3 1 2 2 2 2]\n",
      " [1 2 3 1 4 3 0 3 0]\n",
      " [0 3 4 3 1 4 2 3 4]\n",
      " [1 4 0 1 0 4 4 0 3]\n",
      " [4 4 0 3 4 4 0 2 1]\n",
      " [2 0 1 3 4 3 4 3 1]\n",
      " [4 4 4 4 4 0 3 3 3]]\n",
      "[2 0 0 1 1 3 2 3 4] [[3 1 2 3 3 4 3 4 3]\n",
      " [1 3 4 3 1 1 2 1 2]\n",
      " [1 1 2 1 4 2 0 0 3]\n",
      " [4 2 3 1 2 1 1 1 4]\n",
      " [4 4 1 3 3 1 3 2 2]\n",
      " [1 3 2 2 3 4 2 2 3]\n",
      " [1 4 1 1 3 0 2 1 4]\n",
      " [2 2 3 4 4 3 3 2 3]\n",
      " [3 0 1 4 1 4 3 0 3]]\n",
      "[0 3 3 0 4 4 2 3 4] [[3 3 1 2 0 2 4 1 2]\n",
      " [2 4 4 4 1 1 3 4 2]\n",
      " [0 1 2 1 2 2 2 3 1]\n",
      " [4 0 1 2 4 3 1 2 1]\n",
      " [3 3 2 1 2 0 4 3 3]\n",
      " [4 2 3 2 0 1 0 1 0]\n",
      " [4 3 1 0 0 0 2 1 0]\n",
      " [4 2 2 4 1 0 4 1 0]\n",
      " [2 1 0 4 1 3 1 2 2]]\n",
      "[1 4 4 1 4 2 2 2 2] [[2 2 1 2 4 0 2 1 0]\n",
      " [3 3 0 1 0 2 1 1 1]\n",
      " [1 1 1 1 3 1 2 2 2]\n",
      " [2 3 1 0 0 3 3 0 1]\n",
      " [3 1 4 1 2 0 4 0 2]\n",
      " [2 2 3 3 3 2 1 0 2]\n",
      " [0 4 3 0 3 2 4 1 0]\n",
      " [3 3 1 3 1 2 2 1 0]\n",
      " [4 2 3 4 1 0 4 4 4]]\n",
      "[2 2 4 3 2 3 1 1 1] [[1 3 3 1 4 4 3 0 4]\n",
      " [2 4 1 0 3 1 2 3 1]\n",
      " [2 3 0 0 3 3 3 4 2]\n",
      " [1 3 0 4 4 0 2 0 4]\n",
      " [0 1 2 2 3 0 3 4 0]\n",
      " [0 3 0 1 1 2 0 2 1]\n",
      " [0 0 1 0 0 0 0 1 1]\n",
      " [0 4 0 2 0 4 3 2 1]\n",
      " [0 0 0 3 0 0 0 0 3]]\n",
      "[4 3 2 1 1 1 4 2 1] [[0 0 4 4 3 1 4 1 0]\n",
      " [4 2 0 2 3 3 0 2 1]\n",
      " [0 3 4 3 3 3 0 3 1]\n",
      " [0 2 4 0 1 2 4 0 1]\n",
      " [2 2 4 3 0 0 0 3 3]\n",
      " [0 1 4 2 4 3 4 3 2]\n",
      " [1 0 0 3 4 4 2 4 3]\n",
      " [2 4 4 3 3 3 4 2 0]\n",
      " [1 2 3 2 1 2 3 3 3]]\n",
      "[2 1 4 2 1 2 4 1 0] [[2 4 0 0 1 1 3 4 4]\n",
      " [1 3 0 0 4 0 1 0 0]\n",
      " [2 1 0 0 0 4 2 3 4]\n",
      " [4 4 3 1 2 0 0 0 0]\n",
      " [2 4 1 3 2 1 3 4 1]\n",
      " [2 3 4 0 4 1 3 1 3]\n",
      " [3 0 3 1 3 1 0 2 2]\n",
      " [4 0 0 1 1 4 4 4 1]\n",
      " [4 3 3 4 1 2 2 3 1]]\n",
      "[3 2 4 3 2 3 3 3 3] [[3 3 4 1 4 2 1 0 0]\n",
      " [3 2 4 0 3 3 1 4 0]\n",
      " [4 4 4 3 1 4 1 2 3]\n",
      " [1 2 3 4 0 1 3 1 2]\n",
      " [0 0 0 0 4 1 4 2 1]\n",
      " [3 1 2 0 1 1 0 0 0]\n",
      " [2 0 3 4 0 0 4 3 3]\n",
      " [3 2 4 3 2 3 3 3 4]\n",
      " [4 0 4 2 3 1 1 4 4]]\n",
      "[2 2 4 4 0 2 0 3 0] [[0 3 1 4 1 4 0 0 1]\n",
      " [3 1 3 3 2 3 2 0 4]\n",
      " [3 4 4 1 3 2 4 4 1]\n",
      " [0 0 3 1 3 3 2 4 1]\n",
      " [4 2 1 4 2 2 4 1 1]\n",
      " [1 3 4 3 1 3 4 3 3]\n",
      " [1 2 2 3 3 4 2 3 0]\n",
      " [0 0 0 1 0 3 3 2 1]\n",
      " [1 3 4 3 1 2 1 4 0]]\n",
      "[2 4 0 4 2 4 3 3 0] [[1 2 2 1 2 1 2 1 4]\n",
      " [3 2 4 0 1 0 1 3 3]\n",
      " [3 2 0 3 3 3 2 2 1]\n",
      " [0 0 0 4 3 3 0 4 0]\n",
      " [0 4 4 0 3 4 0 2 4]\n",
      " [1 1 2 2 3 2 4 0 4]\n",
      " [0 3 2 1 0 1 2 0 1]\n",
      " [4 3 0 3 4 4 0 3 0]\n",
      " [1 1 1 1 1 4 3 1 0]]\n",
      "[1 0 3 3 0 2 0 3 3] [[0 0 4 2 0 0 2 2 1]\n",
      " [3 0 0 4 1 0 1 0 0]\n",
      " [3 0 2 0 4 4 3 2 2]\n",
      " [0 2 3 2 3 3 1 3 0]\n",
      " [1 4 1 0 4 4 2 1 3]\n",
      " [1 1 0 1 2 3 1 3 4]\n",
      " [2 4 2 3 4 3 0 4 2]\n",
      " [2 2 0 3 2 3 4 4 0]\n",
      " [2 3 1 4 0 3 4 3 0]]\n",
      "[0 0 2 4 1 4 1 2 2] [[2 1 1 2 2 3 4 0 4]\n",
      " [3 3 1 0 3 4 4 3 0]\n",
      " [1 2 1 4 1 4 4 4 4]\n",
      " [4 3 3 3 3 4 2 3 0]\n",
      " [0 2 4 0 2 3 0 0 3]\n",
      " [0 0 1 3 0 4 3 0 3]\n",
      " [3 1 0 4 1 3 3 4 2]\n",
      " [1 2 1 3 2 2 2 3 4]\n",
      " [0 4 2 1 0 2 0 2 4]]\n",
      "[0 4 3 0 0 1 0 3 4] [[0 2 0 1 3 2 0 2 2]\n",
      " [1 3 3 0 2 3 4 2 3]\n",
      " [2 2 2 0 4 0 2 3 0]\n",
      " [0 1 2 3 3 3 0 3 2]\n",
      " [0 0 2 2 4 2 2 4 2]\n",
      " [1 0 0 4 1 2 0 1 3]\n",
      " [2 2 0 0 3 1 3 0 0]\n",
      " [2 4 2 0 3 2 2 0 0]\n",
      " [2 4 1 0 1 0 0 1 1]]\n",
      "[2 4 4 3 1 4 2 3 1] [[2 4 3 0 0 3 3 4 1]\n",
      " [3 2 4 2 4 1 0 0 0]\n",
      " [0 3 3 2 0 2 4 3 2]\n",
      " [4 0 2 1 0 4 3 4 2]\n",
      " [0 2 4 0 0 0 3 1 2]\n",
      " [0 3 4 1 0 1 3 2 4]\n",
      " [0 1 4 2 4 3 4 2 1]\n",
      " [0 1 0 3 2 2 4 3 1]\n",
      " [3 3 2 3 2 1 3 3 0]]\n",
      "[1 1 2 1 4 4 3 4 1] [[2 4 3 1 3 2 3 2 1]\n",
      " [0 0 2 2 4 4 4 4 4]\n",
      " [2 0 3 2 0 0 1 2 4]\n",
      " [0 2 2 1 1 0 2 3 1]\n",
      " [2 3 1 3 4 3 3 1 1]\n",
      " [2 0 1 0 2 2 2 0 4]\n",
      " [0 2 4 3 4 1 3 1 1]\n",
      " [3 0 3 4 1 3 3 0 3]\n",
      " [4 3 1 0 0 0 2 0 0]]\n",
      "[2 4 0 1 4 4 4 0 4] [[1 0 1 4 2 0 0 3 3]\n",
      " [3 0 1 2 1 0 1 3 1]\n",
      " [3 0 3 0 2 3 0 3 2]\n",
      " [4 0 1 0 2 2 3 4 1]\n",
      " [4 2 3 0 2 4 4 2 0]\n",
      " [2 0 3 2 1 0 1 4 1]\n",
      " [3 4 1 4 3 0 3 4 4]\n",
      " [4 0 4 1 1 0 3 3 3]\n",
      " [4 4 4 0 0 2 3 3 2]]\n",
      "[4 4 3 4 0 1 3 1 4] [[0 0 3 1 4 4 4 0 2]\n",
      " [0 0 2 3 0 4 2 2 2]\n",
      " [4 1 0 0 4 0 0 2 2]\n",
      " [1 2 3 2 3 4 1 1 3]\n",
      " [3 2 3 4 0 1 4 2 0]\n",
      " [2 0 0 4 3 1 4 1 4]\n",
      " [1 3 1 4 1 4 0 2 4]\n",
      " [3 0 2 3 3 2 1 2 2]\n",
      " [2 2 4 0 0 0 2 0 0]]\n",
      "[4 0 0 0 0 3 1 3 0] [[2 4 0 0 0 3 0 0 2]\n",
      " [2 3 3 4 0 2 3 0 1]\n",
      " [2 0 3 2 3 0 2 4 3]\n",
      " [4 1 4 3 3 1 2 3 1]\n",
      " [4 3 0 1 4 1 3 4 0]\n",
      " [0 0 2 2 0 4 1 1 2]\n",
      " [4 0 2 4 4 1 0 3 4]\n",
      " [0 3 0 4 3 4 3 2 4]\n",
      " [4 4 3 0 2 3 4 3 1]]\n",
      "[2 4 3 2 0 4 1 1 0] [[1 0 1 3 3 1 0 1 1]\n",
      " [2 1 2 4 0 0 4 1 4]\n",
      " [2 3 1 2 4 1 4 2 3]\n",
      " [4 4 3 1 4 4 3 0 3]\n",
      " [1 4 1 4 4 4 3 0 4]\n",
      " [3 1 2 2 0 4 4 0 4]\n",
      " [3 4 4 2 4 0 3 4 0]\n",
      " [1 3 1 3 1 2 1 1 4]\n",
      " [0 3 0 1 4 3 2 0 2]]\n",
      "[3 0 2 0 4 4 3 0 1] [[0 1 3 1 1 3 4 3 0]\n",
      " [2 3 0 4 2 1 2 3 1]\n",
      " [3 4 4 2 4 3 3 0 0]\n",
      " [1 1 4 2 1 2 4 4 4]\n",
      " [4 3 2 1 3 4 3 2 1]\n",
      " [0 0 0 2 4 3 3 1 3]\n",
      " [3 0 1 4 2 4 0 4 2]\n",
      " [0 2 1 3 1 3 1 2 1]\n",
      " [1 0 4 4 1 1 2 1 0]]\n",
      "[3 2 0 2 0 2 0 4 2] [[0 4 3 4 3 3 1 2 1]\n",
      " [4 0 4 3 1 3 1 1 0]\n",
      " [0 0 0 3 2 3 0 0 3]\n",
      " [1 0 3 2 2 4 3 4 3]\n",
      " [0 0 1 3 3 2 0 2 0]\n",
      " [0 3 4 1 3 4 2 1 3]\n",
      " [1 1 3 2 3 3 2 3 3]\n",
      " [4 1 1 2 0 1 2 2 1]\n",
      " [2 4 2 2 4 2 0 3 0]]\n",
      "[4 3 3 4 2 4 0 3 0] [[0 2 0 1 3 0 1 4 1]\n",
      " [2 0 1 1 1 4 4 4 2]\n",
      " [2 3 2 3 3 0 1 0 3]\n",
      " [3 2 1 4 1 2 4 3 3]\n",
      " [3 4 2 1 0 0 2 3 2]\n",
      " [1 2 0 4 3 2 1 0 2]\n",
      " [3 2 2 0 4 2 3 2 3]\n",
      " [1 4 1 4 1 2 2 3 4]\n",
      " [3 3 4 0 4 3 1 1 4]]\n",
      "[1 4 0 4 0 1 4 2 3] [[1 4 0 3 2 1 2 4 4]\n",
      " [4 2 0 3 0 4 2 1 3]\n",
      " [4 3 2 1 2 0 3 0 0]\n",
      " [0 2 4 2 1 1 0 3 2]\n",
      " [1 2 0 4 3 4 2 0 3]\n",
      " [2 4 2 3 1 4 1 0 0]\n",
      " [2 4 2 0 1 4 2 2 2]\n",
      " [0 1 2 3 1 3 2 0 2]\n",
      " [3 3 3 0 1 4 3 0 2]]\n",
      "[4 4 2 1 2 3 4 3 1] [[0 1 2 1 3 1 1 1 0]\n",
      " [0 0 0 3 3 2 2 2 3]\n",
      " [3 1 0 2 1 3 0 0 3]\n",
      " [1 1 3 2 4 0 1 1 3]\n",
      " [3 2 2 1 4 0 0 2 2]\n",
      " [1 2 4 3 3 3 1 3 3]\n",
      " [1 2 0 0 2 0 1 0 0]\n",
      " [0 1 2 0 4 3 2 0 4]\n",
      " [4 1 4 4 3 3 0 0 1]]\n",
      "[0 4 2 0 4 3 0 1 4] [[1 0 0 1 2 2 2 2 1]\n",
      " [2 1 0 2 3 4 3 3 1]\n",
      " [0 1 4 3 2 0 2 2 1]\n",
      " [2 0 3 0 4 3 1 0 3]\n",
      " [1 0 0 4 4 3 4 2 3]\n",
      " [0 4 2 3 3 3 2 3 4]\n",
      " [3 0 2 4 1 1 2 2 1]\n",
      " [0 1 0 2 3 4 2 3 4]\n",
      " [4 3 1 4 4 3 4 4 0]]\n",
      "[2 1 4 3 4 4 3 0 3] [[3 1 2 1 3 4 4 0 0]\n",
      " [3 3 2 2 3 1 3 0 3]\n",
      " [0 3 4 4 0 2 2 0 4]\n",
      " [4 3 3 2 1 2 1 4 1]\n",
      " [2 4 2 0 1 4 3 0 0]\n",
      " [1 0 4 3 3 0 1 3 4]\n",
      " [0 3 3 3 2 0 1 4 0]\n",
      " [4 3 3 1 0 4 4 1 1]\n",
      " [2 1 2 0 3 0 2 3 2]]\n",
      "[1 4 3 1 0 4 4 4 4] [[1 3 0 3 0 3 2 2 0]\n",
      " [0 3 1 2 3 4 4 0 0]\n",
      " [4 4 4 3 0 2 4 3 0]\n",
      " [1 4 3 1 1 4 1 0 1]\n",
      " [4 2 1 1 3 2 3 2 4]\n",
      " [1 4 0 4 4 3 1 2 2]\n",
      " [0 2 4 2 4 1 4 0 3]\n",
      " [1 4 2 1 3 0 0 3 1]\n",
      " [1 3 1 0 4 4 2 1 2]]\n",
      "[0 1 3 0 3 0 3 4 4] [[0 0 0 1 4 1 4 2 1]\n",
      " [0 0 3 1 1 2 4 4 4]\n",
      " [3 2 2 2 3 3 4 2 3]\n",
      " [1 2 4 1 2 1 1 0 1]\n",
      " [4 2 4 4 2 2 4 2 2]\n",
      " [1 0 0 3 3 1 0 3 0]\n",
      " [0 0 0 4 4 3 2 2 0]\n",
      " [0 1 3 1 3 4 1 1 1]\n",
      " [0 4 0 1 1 4 1 3 3]]\n",
      "[4 2 2 4 2 1 2 2 1] [[1 1 3 0 4 1 0 1 4]\n",
      " [4 2 4 2 3 4 3 0 4]\n",
      " [1 4 1 3 3 1 0 2 4]\n",
      " [3 0 0 1 2 0 0 3 2]\n",
      " [1 0 2 0 2 3 4 0 1]\n",
      " [0 0 3 0 0 0 0 4 0]\n",
      " [2 2 4 3 2 3 4 3 1]\n",
      " [1 4 2 1 2 1 3 2 3]\n",
      " [1 4 1 0 2 4 2 1 4]]\n",
      "[4 4 2 1 2 4 1 3 2] [[1 1 4 4 1 1 2 1 0]\n",
      " [3 0 2 2 4 0 3 4 1]\n",
      " [2 3 2 0 4 3 1 0 2]\n",
      " [2 3 2 0 2 3 3 3 4]\n",
      " [4 2 0 3 1 4 0 0 2]\n",
      " [3 4 4 3 1 1 1 0 4]\n",
      " [3 2 1 2 1 4 1 0 1]\n",
      " [1 2 2 4 2 0 4 3 3]\n",
      " [3 2 4 2 1 3 3 1 3]]\n",
      "[1 2 3 4 1 2 3 2 0] [[1 3 0 4 1 4 0 2 2]\n",
      " [0 2 4 3 0 1 1 1 3]\n",
      " [0 1 3 4 4 1 1 1 3]\n",
      " [2 4 1 1 1 1 0 4 3]\n",
      " [0 3 0 0 4 1 1 4 3]\n",
      " [0 2 0 4 1 0 2 2 0]\n",
      " [1 2 3 4 1 1 2 4 1]\n",
      " [3 1 4 0 2 2 1 3 2]\n",
      " [2 0 1 3 2 1 4 1 2]]\n",
      "[4 2 4 0 0 0 2 1 4] [[2 4 4 0 0 1 2 1 4]\n",
      " [1 3 1 0 0 1 0 4 3]\n",
      " [2 4 1 2 1 1 3 1 2]\n",
      " [2 3 2 2 1 0 1 2 0]\n",
      " [4 0 3 0 1 2 1 0 2]\n",
      " [1 4 1 1 0 2 0 4 1]\n",
      " [3 3 0 1 1 4 0 4 1]\n",
      " [1 2 0 1 0 2 1 1 1]\n",
      " [4 0 3 3 1 0 1 0 0]]\n",
      "[2 3 4 1 3 1 0 0 0] [[0 4 0 4 2 2 2 4 1]\n",
      " [4 2 0 1 3 2 2 2 1]\n",
      " [1 1 4 3 0 0 1 2 0]\n",
      " [2 0 4 4 2 0 0 2 3]\n",
      " [1 2 1 4 0 2 1 2 4]\n",
      " [1 0 3 0 1 4 0 3 3]\n",
      " [3 3 0 3 2 1 2 2 0]\n",
      " [1 4 3 2 3 1 0 0 0]\n",
      " [4 4 2 1 3 3 3 2 3]]\n",
      "[3 1 1 0 0 3 2 1 4] [[3 1 3 0 2 1 0 4 3]\n",
      " [2 1 4 0 3 4 3 1 3]\n",
      " [3 2 0 4 3 2 2 4 2]\n",
      " [3 2 3 0 0 4 2 0 3]\n",
      " [4 1 3 1 0 4 3 2 2]\n",
      " [1 2 2 3 3 1 0 0 0]\n",
      " [3 1 4 2 2 1 2 4 0]\n",
      " [1 1 2 1 1 1 2 3 4]\n",
      " [0 2 2 2 2 4 1 2 0]]\n",
      "[1 3 1 4 2 1 0 0 4] [[3 3 4 0 2 0 0 2 0]\n",
      " [1 4 2 2 4 1 3 0 2]\n",
      " [4 2 1 4 2 2 3 1 3]\n",
      " [1 0 0 1 4 3 2 3 1]\n",
      " [3 0 0 4 3 4 4 3 0]\n",
      " [4 3 2 1 3 0 0 4 2]\n",
      " [1 2 1 3 4 3 1 0 2]\n",
      " [3 4 4 3 0 0 1 3 4]\n",
      " [4 1 1 1 1 2 3 4 3]]\n",
      "[2 3 2 4 0 0 3 0 4] [[4 2 2 4 4 3 3 4 0]\n",
      " [2 2 2 3 4 4 4 1 2]\n",
      " [1 2 4 0 1 0 3 4 3]\n",
      " [1 1 3 4 2 3 4 4 2]\n",
      " [0 0 4 1 2 2 0 3 3]\n",
      " [3 3 2 4 3 3 2 1 4]\n",
      " [4 3 0 0 0 0 1 3 4]\n",
      " [2 1 1 0 2 0 3 1 3]\n",
      " [3 3 0 0 4 3 4 4 1]]\n",
      "[1 0 4 1 4 1 1 3 0] [[2 4 1 1 3 1 1 0 3]\n",
      " [3 0 3 0 0 0 1 0 0]\n",
      " [4 2 3 0 0 2 2 1 2]\n",
      " [2 1 4 2 2 3 0 0 2]\n",
      " [4 4 3 4 4 1 0 3 2]\n",
      " [2 0 3 1 1 4 2 2 1]\n",
      " [1 1 0 2 2 4 0 2 1]\n",
      " [0 0 4 2 0 2 2 3 0]\n",
      " [4 2 2 4 2 0 2 4 0]]\n",
      "[0 2 2 0 4 2 1 0 1] [[1 0 2 4 2 2 4 4 2]\n",
      " [0 2 2 3 2 0 3 0 4]\n",
      " [2 3 1 0 2 4 2 1 1]\n",
      " [1 4 0 2 4 4 3 2 0]\n",
      " [3 3 3 0 4 2 3 3 2]\n",
      " [4 1 3 4 1 1 1 4 0]\n",
      " [1 0 2 2 0 3 3 0 2]\n",
      " [1 0 4 0 4 4 0 4 3]\n",
      " [1 4 4 1 0 2 4 0 3]]\n",
      "[2 2 1 2 0 2 4 4 1] [[3 0 2 1 4 4 1 2 1]\n",
      " [4 4 2 4 1 0 0 1 1]\n",
      " [4 3 1 4 3 3 0 1 2]\n",
      " [4 4 0 2 0 0 0 1 2]\n",
      " [4 1 2 2 4 0 1 4 2]\n",
      " [3 1 1 0 2 2 4 4 1]\n",
      " [0 4 4 2 4 1 1 2 4]\n",
      " [0 3 0 1 0 0 1 2 1]\n",
      " [1 2 3 4 4 3 3 1 2]]\n",
      "[2 4 0 2 2 0 4 3 2] [[1 4 1 3 4 4 0 3 2]\n",
      " [3 2 3 1 4 2 4 0 4]\n",
      " [4 4 3 3 2 1 0 2 2]\n",
      " [3 4 1 2 1 1 4 3 0]\n",
      " [4 1 1 2 3 0 3 3 2]\n",
      " [2 4 3 3 2 4 1 2 3]\n",
      " [0 4 3 1 2 1 2 1 3]\n",
      " [3 2 4 0 1 3 0 1 1]\n",
      " [1 3 3 0 1 2 0 4 4]]\n",
      "[0 2 2 3 4 3 1 0 0] [[4 2 3 3 3 1 2 4 3]\n",
      " [0 4 1 2 1 3 2 3 3]\n",
      " [2 4 4 2 0 2 2 1 2]\n",
      " [1 0 1 4 4 3 3 1 1]\n",
      " [3 1 2 1 2 1 3 0 3]\n",
      " [2 0 0 2 4 3 4 1 1]\n",
      " [4 3 2 0 1 3 0 4 2]\n",
      " [3 1 3 2 0 4 1 1 1]\n",
      " [4 1 3 0 2 3 1 1 4]]\n"
     ]
    }
   ],
   "source": [
    "for e_, n_ in zip(edges_hard, nodes_hard):\n",
    "    print(n_.data.cpu().numpy(), e_.data.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "[i for i in range(len(mols)) if mols[i] != None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nodes_hard[61]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 3, 1, 2, 1, 1, 1, 1, 1], dtype=int32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [1, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 2, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 2, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 0, 1, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 1, 0, 2],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 2, 0]], dtype=int32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'matplotlib.mlab' has no attribute 'bivariate_normal'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-ce2c3c66c68a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mAllChem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mComputeGasteigerCharges\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mcontribs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGetAtomWithIdx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGetDoubleProp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_GasteigerCharge'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGetNumAtoms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSimilarityMaps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGetSimilarityMapFromWeights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontribs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolorMap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mcontourLines\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/kongsr-rdkit/lib/python3.6/site-packages/rdkit/Chem/Draw/SimilarityMaps.py\u001b[0m in \u001b[0;36mGetSimilarityMapFromWeights\u001b[0;34m(mol, weights, colorMap, scale, size, sigma, coordScale, step, colors, contourLines, alpha, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m       \u001b[0msigma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.3\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_atomPs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_atomPs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0msigma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msigma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m   \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalcAtomGaussians\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m   \u001b[0;31m# scaling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mscale\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/kongsr-rdkit/lib/python3.6/site-packages/rdkit/Chem/Draw/__init__.py\u001b[0m in \u001b[0;36mcalcAtomGaussians\u001b[0;34m(mol, a, step, weights)\u001b[0m\n\u001b[1;32m    285\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m     \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGetNumAtoms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m   \u001b[0mZ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmlab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbivariate_normal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_atomPs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_atomPs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# changed from p.... by junde\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGetNumAtoms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m     \u001b[0mZp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmlab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbivariate_normal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_atomPs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_atomPs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'matplotlib.mlab' has no attribute 'bivariate_normal'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 180x180 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from rdkit.Chem.Draw import SimilarityMaps\n",
    "import matplotlib\n",
    "\n",
    "for j in range(7, 62):\n",
    "    mol = mols[j]\n",
    "    AllChem.ComputeGasteigerCharges(mol)\n",
    "    contribs = [mol.GetAtomWithIdx(i).GetDoubleProp('_GasteigerCharge') for i in range(mol.GetNumAtoms())]\n",
    "    fig = SimilarityMaps.GetSimilarityMapFromWeights(mol, contribs, colorMap=None,  contourLines=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reward(self, mols):\n",
    "    rr = 1.\n",
    "    for m in ('logp,sas,qed,unique' if self.metric == 'all' else self.metric).split(','):\n",
    "\n",
    "        if m == 'np':\n",
    "            rr *= MolecularMetrics.natural_product_scores(mols, norm=True)\n",
    "        elif m == 'logp':\n",
    "            rr *= MolecularMetrics.water_octanol_partition_coefficient_scores(mols, norm=True)\n",
    "        elif m == 'sas':\n",
    "            rr *= MolecularMetrics.synthetic_accessibility_score_scores(mols, norm=True)\n",
    "        elif m == 'qed':\n",
    "            rr *= MolecularMetrics.quantitative_estimation_druglikeness_scores(mols, norm=True)\n",
    "        elif m == 'novelty':\n",
    "            rr *= MolecularMetrics.novel_scores(mols, data)\n",
    "        elif m == 'dc':\n",
    "            rr *= MolecularMetrics.drugcandidate_scores(mols, data)\n",
    "        elif m == 'unique':\n",
    "            rr *= MolecularMetrics.unique_scores(mols)\n",
    "        elif m == 'diversity':\n",
    "            rr *= MolecularMetrics.diversity_scores(mols, data)\n",
    "        elif m == 'validity':\n",
    "            rr *= MolecularMetrics.valid_scores(mols)\n",
    "        else:\n",
    "            raise RuntimeError('{} is not defined as a metric'.format(m))\n",
    "\n",
    "    return rr.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean([i for i in MolecularMetrics.natural_product_scores(mols, norm=True) if i != 0 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 9])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_fake.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.083045973594572"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from frechetdist import frdist\n",
    "R=[list(a_real[i].reshape(-1))  for i in range(128)] #list(x_real[i]) +\n",
    "F=[list(a_real_2[i].reshape(-1))  for i in range(128)] #list(x_fake[i]) + \n",
    "frdist(R,F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.2, 0.2, 0.6, 0.2, 0.6, 0.2, 0.4, 0.2, 0.2])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_real_2[0]*0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a_1 = a\n",
    "a_2 = a_1\n",
    "a_3 = a_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.2, 0.2, 0.6, 0.2, 0.6, 0.2, 0.4, 0.2, 0.2])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kongsr-rdkit",
   "language": "python",
   "name": "kongsr-rdkit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
