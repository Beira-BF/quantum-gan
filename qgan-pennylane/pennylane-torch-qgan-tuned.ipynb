{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import csv\n",
    "import pandas as pd\n",
    "import argparse\n",
    "import os\n",
    "import math\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torch.utils.data as data\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "# dev = qml.device('cirq.simulator', wires=2)\n",
    "dev = qml.device('default.qubit', wires=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(b1=0.5, b2=0.999, batch_size=16, k=2, latent_dim=100, lr=0.001, n_cpu=8, n_epochs=50, sample_interval=100)\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--n_epochs\", type=int, default=50, help=\"number of epochs of training\")\n",
    "parser.add_argument(\"--batch_size\", type=int, default=16, help=\"size of the batches\")\n",
    "parser.add_argument(\"--lr\", type=float, default=0.001, help=\"adam: learning rate\")\n",
    "parser.add_argument(\"--b1\", type=float, default=0.5, help=\"adam: decay of first order momentum of gradient\")\n",
    "parser.add_argument(\"--b2\", type=float, default=0.999, help=\"adam: decay of first order momentum of gradient\")\n",
    "parser.add_argument(\"--n_cpu\", type=int, default=8, help=\"number of cpu threads to use during batch generation\")\n",
    "parser.add_argument(\"--latent_dim\", type=int, default=100, help=\"dimensionality of the latent space\")\n",
    "parser.add_argument(\"--sample_interval\", type=int, default=100, help=\"interval betwen image samples\")\n",
    "parser.add_argument(\"--k\", type=int, default=2, help=\"multiple discriminator iterations\")\n",
    "config = parser.parse_known_args()[0]\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda = True if torch.cuda.is_available() else False\n",
    "\n",
    "@qml.qnode(dev, interface='torch')\n",
    "def gen_circuit(w):\n",
    "    # Sample noise as generator input\n",
    "    z = random.uniform(-1, 1)\n",
    "\n",
    "    qml.RY(np.arcsin(z), wires=0)\n",
    "    qml.RY(np.arcsin(z), wires=1)\n",
    "    qml.RZ(np.arccos(z), wires=0)\n",
    "    qml.RZ(np.arccos(z), wires=1)\n",
    "    qml.RY(w[0], wires=0)\n",
    "    qml.RY(w[1], wires=1)\n",
    "    qml.Hadamard(wires=0)\n",
    "    qml.Hadamard(wires=1)\n",
    "\n",
    "    qml.CNOT(wires=[0, 1])\n",
    "    qml.RZ(w[2], wires=1)\n",
    "    qml.CNOT(wires=[0, 1])\n",
    "\n",
    "    qml.Hadamard(wires=0)\n",
    "    qml.Hadamard(wires=1)\n",
    "\n",
    "    return qml.expval(qml.PauliZ(0))\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(1, 32),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(32, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, sample):\n",
    "        sample_flat = sample.view(sample.size(0), -1)\n",
    "        validity = self.model(sample_flat)\n",
    "\n",
    "        return validity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/junde/anaconda3/envs/kongsr-rdkit/lib/python3.6/site-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loss function\n",
    "adversarial_loss = torch.nn.BCELoss(size_average=False)\n",
    "discriminator = Discriminator()\n",
    "\n",
    "Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n",
    "\n",
    "if cuda:\n",
    "    discriminator.cuda()\n",
    "    adversarial_loss.cuda()\n",
    "    \n",
    "device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BimodalDataset(data.Dataset):\n",
    "    \"\"\"Bimodal distribution dataset.\"\"\"\n",
    "    def __init__(self, csv_file):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "        \"\"\"\n",
    "        self.df = pd.read_csv(csv_file, header=None)\n",
    "    def __len__(self):\n",
    "        return len(self.df.to_numpy()[0])\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.df.to_numpy()[0][idx]\n",
    "        return item \n",
    " \n",
    "filename = 'data_bimodal.csv'\n",
    "dataset = BimodalDataset(filename)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=config.batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.49515361889649034, 0.17200362900831057, 0.1768981042319424]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(np.random.rand(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial generator weights: [0.016268182625356675, 0.06565351014879672, 0.6636422604047488]\n",
      "\n",
      "Start training...\n",
      "2020-09-25 17:24:09\t[Epoch 1/50  Batch 0/625]\t[D loss: 6.944081]\t[G loss: 80.087517]\n",
      "tensor([0.5656, 0.2092, 0.0303], dtype=torch.float64)\n",
      "2020-09-25 17:24:25\t[Epoch 1/50  Batch 100/625]\t[D loss: 7.755075]\t[G loss: 19.084652]\n",
      "tensor([ 0.2601,  0.2956, -1.2612], dtype=torch.float64)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-113d7b111099>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0mbest_g_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0mg_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0moptimizer_G\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/kongsr-rdkit/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \"\"\"\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/kongsr-rdkit/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     99\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Adversarial ground truths\n",
    "valid = Variable(Tensor(config.batch_size).fill_(1.0), requires_grad=False)\n",
    "fake = Variable(Tensor(config.batch_size).fill_(0.0), requires_grad=False)\n",
    "init_weights = list(np.random.rand(3))\n",
    "print('Initial generator weights:', init_weights)\n",
    "print()\n",
    "gen_weights = torch.tensor(list(np.random.rand(3)), requires_grad=True)\n",
    "# optimizer_G = torch.optim.Adam([gen_weights], lr = config.lr)\n",
    "# optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=config.lr)\n",
    "optimizer_G = torch.optim.SGD([gen_weights], lr=config.lr, momentum=0.9)\n",
    "optimizer_D = torch.optim.SGD(discriminator.parameters(), lr=config.lr, momentum=0.9)\n",
    "best_g_loss = np.inf\n",
    "\n",
    "\n",
    "# Start training.\n",
    "print('Start training...')\n",
    "\n",
    "for epoch in range(config.n_epochs):    \n",
    "    # learning rate decay\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        config.lr = config.lr * .6\n",
    "        print()\n",
    "        print('Training with learning rate:', config.lr)\n",
    "        \n",
    "    for i, samples in enumerate(dataloader):\n",
    "        # Configure input\n",
    "        real_samples = Variable(samples.type(Tensor))\n",
    "        \n",
    "        # -----------------\n",
    "        #  Train Generator\n",
    "        # -----------------\n",
    "#         if (i%5 == 0):\n",
    "        optimizer_G.zero_grad()\n",
    "\n",
    "        # Generate a batch of samples\n",
    "        sample_list = [gen_circuit(gen_weights) for i in range(config.batch_size)]\n",
    "        gen_samples = torch.stack(tuple(sample_list)).to(device).float()\n",
    "#         loss = adversarial_loss(discriminator(torch.unsqueeze(gen_samples, 1)), valid)\n",
    "        loss = adversarial_loss(discriminator(gen_samples), valid)\n",
    "        g_loss = loss.mean()\n",
    "        \n",
    "        # keep track of best G loss and generator parameters\n",
    "        if g_loss < best_g_loss:\n",
    "            best_g_loss = g_loss\n",
    "            best_g_weights = gen_weights            \n",
    "\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "        \n",
    "        # ---------------------\n",
    "        #  Train Discriminator\n",
    "        # ---------------------\n",
    "        \n",
    "        for j in range(config.k):\n",
    "            optimizer_D.zero_grad()\n",
    "\n",
    "            # Measure discriminator's ability to classify real from generated samples\n",
    "            real_loss = adversarial_loss(discriminator(real_samples), valid)\n",
    "            fake_loss = adversarial_loss(discriminator(gen_samples.detach().float()), fake)\n",
    "            d_loss = (real_loss + fake_loss) / 2\n",
    "\n",
    "            d_loss.backward(retain_graph=True)\n",
    "            optimizer_D.step()\n",
    "        \n",
    "        if i % config.sample_interval == 0:\n",
    "            print(\n",
    "                \"%s\\t[Epoch %d/%d  Batch %d/%d]\\t[D loss: %f]\\t[G loss: %f]\"\n",
    "                % (datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"), epoch+1, config.n_epochs, i, len(dataloader), d_loss.item(), g_loss.item())\n",
    "            )\n",
    "            print(gen_weights.detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_weights.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "samples = []\n",
    "num_samples = 1000\n",
    "w = [1.8302, 2.1733, 4.2969]\n",
    "for i in range(num_samples):\n",
    "    samples.append(gen_circuit(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# the histogram of the data\n",
    "plt.hist(samples, 30, facecolor='g', alpha=0.75)\n",
    "\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of bimodal distribution')\n",
    "plt.xlim(-1, 1)\n",
    "plt.ylim(0, 140)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kongsr-rdkit",
   "language": "python",
   "name": "kongsr-rdkit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
