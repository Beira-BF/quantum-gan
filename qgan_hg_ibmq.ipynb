{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/junde/miniconda3/envs/kongsr-rdkit/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/junde/miniconda3/envs/kongsr-rdkit/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/junde/miniconda3/envs/kongsr-rdkit/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/junde/miniconda3/envs/kongsr-rdkit/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/junde/miniconda3/envs/kongsr-rdkit/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:521: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/junde/miniconda3/envs/kongsr-rdkit/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import pennylane as qml\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import pandas as pd\n",
    "import argparse\n",
    "import os\n",
    "import math\n",
    "import datetime\n",
    "import time\n",
    "from frechetdist import frdist\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torch.utils.data as data\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "from solver import Solver\n",
    "from data_loader import get_loader\n",
    "from torch.backends import cudnn\n",
    "from utils import *\n",
    "from models import Generator, Discriminator\n",
    "from data.sparse_molecular_dataset import SparseMolecularDataset\n",
    "from rdkit import Chem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/junde/miniconda3/envs/kongsr-rdkit/lib/python3.6/site-packages/qiskit/providers/ibmq/ibmqfactory.py:109: UserWarning: Timestamps in IBMQ backend properties, jobs, and job results are all now in local time instead of UTC.\n",
      "  warnings.warn('Timestamps in IBMQ backend properties, jobs, and job results '\n"
     ]
    }
   ],
   "source": [
    "def str2bool(v):\n",
    "    return v.lower() in ('true')\n",
    "\n",
    "dev = qml.device('qiskit.ibmq', wires=8, backend='ibmq_16_melbourne')\n",
    "# dev = qml.device('default.qubit', wires=8)\n",
    "@qml.qnode(dev, interface='torch')\n",
    "def gen_circuit(w):\n",
    "    # random noise as generator input\n",
    "    z1 = random.uniform(-1, 1)\n",
    "    z2 = random.uniform(-1, 1)\n",
    "    layers = 1\n",
    "    qubits = 8\n",
    "    \n",
    "    # construct generator circuit for both atom vector and node matrix\n",
    "    for i in range(qubits):\n",
    "        qml.RY(np.arcsin(z1), wires=i)\n",
    "        qml.RZ(np.arcsin(z2), wires=i)\n",
    "    for l in range(layers):\n",
    "        for i in range(qubits):\n",
    "            qml.RY(w[i], wires=i)\n",
    "#             qml.Hadamard(wires=i)\n",
    "        for i in range(qubits-1):\n",
    "            qml.CNOT(wires=[i, i+1])\n",
    "            qml.RZ(w[i+qubits], wires=i+1)\n",
    "            qml.CNOT(wires=[i, i+1])\n",
    "#     for i in range(qubits):\n",
    "#         qml.Hadamard(wires=i)\n",
    "    return [qml.expval(qml.PauliZ(i)) for i in range(qubits)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=1000, beta1=0.5, beta2=0.999, d_conv_dim=[[128, 64], 128, [128, 64]], d_lr=0.0001, d_repeat_num=6, dropout=0.0, g_conv_dim=[128], g_lr=0.0001, g_repeat_num=6, lambda_cls=1, lambda_gp=10, lambda_rec=10, log_dir='molgan/logs', log_step=10, lr_update_step=500, mode='train', model_save_dir='molgan/models', model_save_step=1000, mol_data_dir='data/gdb9_9nodes.sparsedataset', n_critic=5, num_iters=5000, num_iters_decay=2500, num_workers=1, post_method='softmax', result_dir='molgan/results', resume_iters=None, sample_dir='molgan/samples', sample_step=1000, test_iters=5000, use_tensorboard=False, z_dim=8)\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "# Model configuration.\n",
    "parser.add_argument('--z_dim', type=int, default=8, help='dimension of domain labels')\n",
    "parser.add_argument('--g_conv_dim', default=[128], help='number of conv filters in the first layer of G')\n",
    "parser.add_argument('--d_conv_dim', type=int, default=[[128, 64], 128, [128, 64]], help='number of conv filters in the first layer of D')\n",
    "parser.add_argument('--g_repeat_num', type=int, default=6, help='number of residual blocks in G')\n",
    "parser.add_argument('--d_repeat_num', type=int, default=6, help='number of strided conv layers in D')\n",
    "parser.add_argument('--lambda_cls', type=float, default=1, help='weight for domain classification loss')\n",
    "parser.add_argument('--lambda_rec', type=float, default=10, help='weight for reconstruction loss')\n",
    "parser.add_argument('--lambda_gp', type=float, default=10, help='weight for gradient penalty')\n",
    "parser.add_argument('--post_method', type=str, default='softmax', choices=['softmax', 'soft_gumbel', 'hard_gumbel'])\n",
    "\n",
    "# Training configuration.\n",
    "parser.add_argument('--batch_size', type=int, default=1000, help='mini-batch size')\n",
    "parser.add_argument('--num_iters', type=int, default=5000, help='number of total iterations for training D')\n",
    "parser.add_argument('--num_iters_decay', type=int, default=2500, help='number of iterations for decaying lr')\n",
    "parser.add_argument('--g_lr', type=float, default=0.0001, help='learning rate for G')\n",
    "parser.add_argument('--d_lr', type=float, default=0.0001, help='learning rate for D')\n",
    "parser.add_argument('--dropout', type=float, default=0., help='dropout rate')\n",
    "parser.add_argument('--n_critic', type=int, default=5, help='number of D updates per each G update')\n",
    "parser.add_argument('--beta1', type=float, default=0.5, help='beta1 for Adam optimizer')\n",
    "parser.add_argument('--beta2', type=float, default=0.999, help='beta2 for Adam optimizer')\n",
    "parser.add_argument('--resume_iters', type=int, default=None, help='resume training from this step')\n",
    "\n",
    "# Test configuration.\n",
    "parser.add_argument('--test_iters', type=int, default=5000, help='test model from this step')\n",
    "\n",
    "# Miscellaneous.\n",
    "parser.add_argument('--num_workers', type=int, default=1)\n",
    "parser.add_argument('--mode', type=str, default='train', choices=['train', 'test'])\n",
    "parser.add_argument('--use_tensorboard', type=str2bool, default=False)\n",
    "\n",
    "# Directories.\n",
    "parser.add_argument('--mol_data_dir', type=str, default='data/gdb9_9nodes.sparsedataset')\n",
    "parser.add_argument('--log_dir', type=str, default='molgan/logs')\n",
    "parser.add_argument('--model_save_dir', type=str, default='molgan/models')\n",
    "parser.add_argument('--sample_dir', type=str, default='molgan/samples')\n",
    "parser.add_argument('--result_dir', type=str, default='molgan/results')\n",
    "\n",
    "# Step size.\n",
    "parser.add_argument('--log_step', type=int, default=10)\n",
    "parser.add_argument('--sample_step', type=int, default=1000)\n",
    "parser.add_argument('--model_save_step', type=int, default=1000)\n",
    "parser.add_argument('--lr_update_step', type=int, default=500)\n",
    "\n",
    "config = parser.parse_known_args()[0]\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=8, out_features=128, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Dropout(p=0.0, inplace=True)\n",
      "  )\n",
      "  (edges_layer): Linear(in_features=128, out_features=405, bias=True)\n",
      "  (nodes_layer): Linear(in_features=128, out_features=45, bias=True)\n",
      "  (dropoout): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "G\n",
      "The number of parameters: 59202\n",
      "Discriminator(\n",
      "  (gcn_layer): GraphConvolution(\n",
      "    (linear1): Linear(in_features=5, out_features=128, bias=True)\n",
      "    (linear2): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (dropout): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (agg_layer): GraphAggregation(\n",
      "    (sigmoid_linear): Sequential(\n",
      "      (0): Linear(in_features=69, out_features=128, bias=True)\n",
      "      (1): Sigmoid()\n",
      "    )\n",
      "    (tanh_linear): Sequential(\n",
      "      (0): Linear(in_features=69, out_features=128, bias=True)\n",
      "      (1): Tanh()\n",
      "    )\n",
      "    (dropout): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (linear_layer): Sequential(\n",
      "    (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (1): Dropout(p=0.0, inplace=False)\n",
      "    (2): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (3): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (output_layer): Linear(in_features=64, out_features=1, bias=True)\n",
      ")\n",
      "D\n",
      "The number of parameters: 51777\n"
     ]
    }
   ],
   "source": [
    "self = Solver(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the trained models from step 3000...\n"
     ]
    }
   ],
   "source": [
    "# Inference of generated molecules\n",
    "start_iters = 0\n",
    "self.resume_iters = 3000\n",
    "\n",
    "if self.resume_iters:\n",
    "    start_iters = self.resume_iters\n",
    "    self.restore_model(self.resume_iters)\n",
    "    gen_weights = torch.tensor([-0.114014186,-0.238699,-0.26056057,0.525604,0.041803483,0.77931786,-0.226683,0.04203498,\\\n",
    "                                -0.7405998,0.040963333,0.13625668,0.5491951,0.41576374,-0.059020802,0.7136884], requires_grad=True)\n",
    "sim_sample_list = [gen_circuit(gen_weights) for i in range(self.batch_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start inference...\n"
     ]
    }
   ],
   "source": [
    "# Start inference.\n",
    "print('Start inference...')\n",
    "start_time = time.time()\n",
    "\n",
    "mols, _, _, a, x, _, _, _, _ = self.data.next_train_batch(self.batch_size)\n",
    "\n",
    "# =================================================================================== #\n",
    "#                             1. Preprocess input data                                #\n",
    "# =================================================================================== #\n",
    "\n",
    "a = torch.from_numpy(a).to(self.device).long()            # Adjacency.\n",
    "x = torch.from_numpy(x).to(self.device).long()            # Nodes.\n",
    "a_tensor = self.label2onehot(a, self.b_dim)\n",
    "x_tensor = self.label2onehot(x, self.m_dim)\n",
    "z = torch.stack(tuple(ibm_sample_list)).to(self.device).float()\n",
    "\n",
    "\n",
    "# Z-to-target\n",
    "edges_logits, nodes_logits = self.G(z)\n",
    "# Postprocess with Gumbel softmax\n",
    "(edges_hat, nodes_hat) = self.postprocess((edges_logits, nodes_logits), self.post_method)\n",
    "logits_fake, features_fake = self.D(edges_hat, None, nodes_hat)\n",
    "g_loss_fake = - torch.mean(logits_fake)\n",
    "\n",
    "# Real Reward\n",
    "rewardR = torch.from_numpy(self.reward(mols)).to(self.device)\n",
    "# Fake Reward\n",
    "(edges_hard, nodes_hard) = self.postprocess((edges_logits, nodes_logits), 'hard_gumbel')\n",
    "edges_hard, nodes_hard = torch.max(edges_hard, -1)[1], torch.max(nodes_hard, -1)[1]\n",
    "mols = [self.data.matrices2mol(n_.data.cpu().numpy(), e_.data.cpu().numpy(), strict=True)\n",
    "        for e_, n_ in zip(edges_hard, nodes_hard)]\n",
    "rewardF = torch.from_numpy(self.reward(mols)).to(self.device)\n",
    "\n",
    "# Value loss\n",
    "value_logit_real,_ = self.V(a_tensor, None, x_tensor, torch.sigmoid)\n",
    "value_logit_fake,_ = self.V(edges_hat, None, nodes_hat, torch.sigmoid)\n",
    "g_loss_value = torch.mean((value_logit_real - rewardR) ** 2 + (\n",
    "                                       value_logit_fake - rewardF) ** 2)\n",
    "\n",
    "R=[list(a[i].reshape(-1))  for i in range(self.batch_size)] #list(x[i]) + \n",
    "F=[list(edges_hard[i].reshape(-1))  for i in range(self.batch_size)] #list(nodes_hard[i]) + \n",
    "fd_bond_only = frdist(R, F)\n",
    "\n",
    "R=[list(x[i]) + list(a[i].reshape(-1))  for i in range(self.batch_size)]\n",
    "F=[list(nodes_hard[i]) + list(edges_hard[i].reshape(-1))  for i in range(self.batch_size)]\n",
    "fd_bond_atom = frdist(R, F)\n",
    "\n",
    "loss = {}\n",
    "loss['G/loss_fake'] = g_loss_fake.item()\n",
    "loss['G/loss_value'] = g_loss_value.item()\n",
    "loss['FD/fd_bond_only'] = fd_bond_only\n",
    "loss['FD/fd_bond_atom'] = fd_bond_atom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed [0:00:36], Iteration [inf/5000], G/loss_fake: -0.2760, G/loss_value: 0.3329, FD/fd_bond_only: 22.8910, FD/fd_bond_atom: 23.6008, NP score: nan, QED score: nan, logP score: nan, SA score: nan, diversity score: nan, drugcandidate score: 0.1178, valid score: 0.0000, unique score: 0.0000, novel score: nan\n",
      "['0:00:36', 0.2048536092042923, 0.0, -0.27596616744995117, 0.33291125297546387, 22.891046284519195, 23.600847442411894, nan, nan, nan, nan, nan, 0.11783951472333935, 0.0, 0, nan]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/junde/psu/qgan/quantum-gan/utils.py:65: RuntimeWarning: Mean of empty slice.\n",
      "  return MolecularMetrics.novel_scores(MolecularMetrics.valid_filter(mols), data).mean()\n",
      "/home/junde/miniconda3/envs/kongsr-rdkit/lib/python3.6/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/junde/miniconda3/envs/kongsr-rdkit/lib/python3.6/site-packages/ipykernel_launcher.py:8: RuntimeWarning: Mean of empty slice.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Print out training information.\n",
    "et = time.time() - start_time\n",
    "et = str(datetime.timedelta(seconds=et))[:-7]\n",
    "log = \"Elapsed [{}], Iteration [inf/{}]\".format(et, self.num_iters)\n",
    "\n",
    "# Log update\n",
    "m0, m1 = all_scores(mols, self.data, norm=True)     # 'mols' is output of Fake Reward\n",
    "m0 = {k: np.array(v)[np.nonzero(v)].mean() for k, v in m0.items()}\n",
    "m0.update(m1)\n",
    "loss.update(m0)\n",
    "for tag, value in loss.items():\n",
    "    log += \", {}: {:.4f}\".format(tag, value)\n",
    "print(log)\n",
    "\n",
    "print([et]+[torch.mean(rewardR).item(), torch.mean(rewardF).item()]+\\\n",
    "                   [value for tag, value in loss.items()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elapsed [0:00:03], Iteration [inf/5000], G/loss_fake: -0.8523, G/loss_value: 0.0522, FD/fd_bond_only: 16.3401, FD/fd_bond_atom: 16.6433, NP score: 0.7629, QED score: 0.4829, logP score: 0.4962, SA score: 0.1749, diversity score: 1.0000, drugcandidate score: 0.2594, valid score: 37.5000, unique score: 91.6667, novel score: 100.0000\n",
    "['0:00:03', 0.21765445172786713, 0.0, -0.8523263931274414, 0.052209995687007904, 16.34013463836819, 16.64331697709324, 0.7628816836161834, 0.4828823321190301, 0.49617016790921425, 0.1749333335230446, 1.0, 0.2594248617430995, 37.5, 91.66666666666666, 100.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the trained models from step 3000...\n",
      "IBM Q running job 0\n",
      "IBM Q running job 1\n",
      "IBM Q running job 2\n",
      "IBM Q running job 3\n",
      "IBM Q running job 4\n",
      "IBM Q running job 5\n",
      "IBM Q running job 6\n",
      "IBM Q running job 7\n",
      "IBM Q running job 8\n",
      "IBM Q running job 9\n",
      "IBM Q running job 10\n",
      "IBM Q running job 11\n",
      "IBM Q running job 12\n",
      "IBM Q running job 13\n",
      "IBM Q running job 14\n"
     ]
    }
   ],
   "source": [
    "# Inference of generated molecules\n",
    "start_iters = 0\n",
    "self.resume_iters = 3000\n",
    "\n",
    "if self.resume_iters:\n",
    "    start_iters = self.resume_iters\n",
    "    self.restore_model(self.resume_iters)\n",
    "    gen_weights = torch.tensor([-0.114014186,-0.238699,-0.26056057,0.525604,0.041803483,0.77931786,-0.226683,0.04203498,\\\n",
    "                                -0.7405998,0.040963333,0.13625668,0.5491951,0.41576374,-0.059020802,0.7136884], requires_grad=True)\n",
    "ibm_sample_list = []\n",
    "for i in range(self.batch_size):\n",
    "    print(\"IBM Q running job {}\".format(i))\n",
    "    ibm_sample_list.append(gen_circuit(gen_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kongsr-rdkit",
   "language": "python",
   "name": "kongsr-rdkit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
